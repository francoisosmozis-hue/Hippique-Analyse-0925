name: GPI v5.1 – H-30 / H-5

on:
  workflow_dispatch:
    inputs:
      meeting: { description: "Réunion ex: R1", required: false }
      race:    { description: "Course ex: C5", required: false }
      course_id: { description: "Identifiant numérique de la course", required: true }
  schedule:
    # Paris (été) : 16:25 ≈ H-30 ; 16:55 ≈ H-5  (adapte si besoin)
    - cron: "25 15 * * *"
    - cron: "55 15 * * *"

env:
  TZ: Europe/Paris
  PYTHONUTF8: "1"
  # Paramètres GPI v5.1
  # Budget total 5 € réparti entre SP et combinés
  BUDGET_TOTAL: "5"
  SP_RATIO: "0.6"      # 60% pour les paris simples
  COMBO_RATIO: "0.4"   # 40% pour les combinés
  # Seuils EV/ROI et autres garde-fous
  EV_MIN_SP: "0.15"
  EV_MIN_SP_HOMOGENEOUS: "0.10"
  EV_MIN_GLOBAL: "0.35"
  ROI_MIN_SP: "0.10"
  ROI_MIN_GLOBAL: "0.25"
  SHARPE_MIN: "0.5"
  MAX_VOL_PAR_CHEVAL: "0.35"
  ROUND_TO_SP: "0.10"   # arrondi des mises SP (0 désactive l'arrondi sans provoquer d'erreur)
  MIN_PAYOUT_COMBOS: "12.0"  # payout attendu minimal en €
  EXOTIC_MIN_PAYOUT: "12.0"
  correlation_penalty: "0.85"
  ALLOW_JE_NA: "false"
  SNAPSHOTS: "H30,H5"
  DRIFT_TOP_N: "5"
  DRIFT_MIN_DELTA: "0.8"
  P_TRUE_MIN_SAMPLES: "100"

jobs:
  gpi:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt || true
          python - <<'PY'
          from pathlib import Path

          req_path = Path("requirements.txt")
          base, optional = [], []
          optional_markers = ("scipy",)

          for raw_line in req_path.read_text(encoding="utf-8").splitlines():
              line = raw_line.strip()
              if not line or line.startswith("#"):
                  continue

              target = optional if line.lower().startswith(optional_markers) else base
              target.append(line)

          Path("requirements-base.txt").write_text("\n".join(base), encoding="utf-8")
          Path("requirements-optional.txt").write_text("\n".join(optional), encoding="utf-8")
          PY
          pip install -r requirements-base.txt
          if [ -s requirements-optional.txt ]; then
            while read -r pkg; do
              pip install "$pkg" || echo "::warning::Optional dependency $pkg failed to install"
            done < requirements-optional.txt
          fi
          pip install requests beautifulsoup4 pyyaml python-dotenv pytest
          rm -f requirements-base.txt requirements-optional.txt

      - name: Critical dependency check
        run: python -c "import pandas, google.cloud.storage"
         
      - name: Resolve inputs
        id: in
        env:
          INPUT_MEETING: ${{ github.event.inputs.meeting || '' }}
          INPUT_RACE: ${{ github.event.inputs.race || '' }}
          INPUT_COURSE_ID: ${{ github.event.inputs.course_id || '' }}
          DEFAULT_COURSE_ID: ${{ secrets.GPI_DEFAULT_COURSE_ID || '' }}
          EVENT_NAME: ${{ github.event_name }}
        run: |
          python <<'PY'
          import os
          from pathlib import Path

          from scripts.resolve_course_id import CourseContextError, resolve_course_context

          meeting = (os.environ.get("INPUT_MEETING") or "").strip()
          race = (os.environ.get("INPUT_RACE") or "").strip()
          course_id = (os.environ.get("INPUT_COURSE_ID") or "").strip()
          event_name = os.environ.get("EVENT_NAME", "").strip()
          default_course_id = (os.environ.get("DEFAULT_COURSE_ID") or "").strip()

          resolved_meeting = meeting
          resolved_race = race
          resolved_course_id = course_id

          if not resolved_course_id:
              if event_name == "schedule":
                  if default_course_id:
                      print(f"::notice::Using default COURSE_ID from secrets for scheduled run: {default_course_id}")
                      resolved_course_id = default_course_id
                  else:
                      print("::notice::Attempting automatic COURSE_ID resolution for scheduled run…")
                      try:
                          ctx = resolve_course_context(schedule_file="schedules.csv", planning_dir="data/planning")
                      except CourseContextError as exc:
                          print(f"::error::Unable to resolve COURSE_ID automatically: {exc}")
                          raise SystemExit(1)

                      resolved_course_id = ctx.course_id
                      if not resolved_meeting and ctx.meeting:
                          resolved_meeting = ctx.meeting
                      if not resolved_race and ctx.race:
                          resolved_race = ctx.race

                      print(
                          "::notice::Resolved course context automatically: "
                          f"course_id={resolved_course_id}, meeting={resolved_meeting or 'N/A'}, race={resolved_race or 'N/A'}"
                      )
              else:
                  print("::error::Provide course_id when running the workflow manually (workflow_dispatch).");
                  raise SystemExit(1)

          output_path = Path(os.environ["GITHUB_OUTPUT"])
          with output_path.open("a", encoding="utf-8") as fh:
              fh.write(f"MEETING={resolved_meeting or ''}\n")
              fh.write(f"RACE={resolved_race or ''}\n")
              fh.write(f"COURSE_ID={resolved_course_id}\n")
          PY

      - name: Ensure course ID is available
        if: steps.in.outputs.COURSE_ID == ''
        run: |
          echo "::error::Aucun COURSE_ID n'a pu être déterminé. Relancez le workflow manuellement avec un identifiant valide."
          exit 1

      - name: Inject course ID into source URL
        if: steps.in.outputs.COURSE_ID != ''
        run: |
          cid="${{ steps.in.outputs.COURSE_ID }}"          
          sed -i "s/{course_id}/$cid/" config/sources.yml

      # H-30 SNAPHOT
      - name: H-30 snapshot (meetings + odds)
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('25 15 * * *', github.event.schedule))
        run: |
          mkdir -p data/h30
          python scripts/online_fetch_zeturf.py --mode h30 --out data/h30/h30.json
          # Option ciblage R/C si fournis (écrit RnCx-h30.json)
          if [ -n "${{ steps.in.outputs.MEETING }}" ] && [ -n "${{ steps.in.outputs.RACE }}" ]; then
            python pipeline_run.py snapshot --when h30 --meeting "${{ steps.in.outputs.MEETING }}" --race "${{ steps.in.outputs.RACE }}" --outdir data/h30
          fi

      - name: Extraire les cotes H-30
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('25 15 * * *', github.event.schedule))
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          src = Path("data/h30/h30.json")
          dest = Path("data/h30/odds.json")
          if not src.exists():
              raise SystemExit("Fichier H-30 manquant : data/h30/h30.json")

          try:
              payload = json.loads(src.read_text(encoding="utf-8"))
          except json.JSONDecodeError as exc:
              raise SystemExit(f"JSON invalide dans {src}: {exc}")

          odds: dict[str, float] = {}
          for runner in payload.get("runners", []):
              cid = runner.get("id")
              if cid is None:
                  continue
              value = runner.get("odds")
              if value in (None, "", "-"):
                  continue
              try:
                  odds[str(cid)] = float(value)
              except (TypeError, ValueError):
                  continue

          dest.write_text(json.dumps(odds, ensure_ascii=False, indent=2), encoding="utf-8")
          print(f"{len(odds)} entrées extraites vers {dest}")
          PY

      # H-5 ANALYSE + DIFF
      - name: H-5 snapshot
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('55 15 * * *', github.event.schedule))
        run: |
          mkdir -p data/h5 data/diff data/out
          python scripts/online_fetch_zeturf.py --mode h5 --out data/h5/h5.json

      - name: Extraire les cotes H-5
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('55 15 * * *', github.event.schedule))
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          src = Path("data/h5/h5.json")
          dest = Path("data/h5/odds.json")
          if not src.exists():
              raise SystemExit("Fichier H-5 manquant : data/h5/h5.json")

          try:
              payload = json.loads(src.read_text(encoding="utf-8"))
          except json.JSONDecodeError as exc:
              raise SystemExit(f"JSON invalide dans {src}: {exc}")

          odds: dict[str, float] = {}
          for runner in payload.get("runners", []):
              cid = runner.get("id")
              if cid is None:
                  continue
              value = runner.get("odds")
              if value in (None, "", "-"):
                  continue
              try:
                  odds[str(cid)] = float(value)
              except (TypeError, ValueError):
                  continue

          dest.write_text(json.dumps(odds, ensure_ascii=False, indent=2), encoding="utf-8")
          print(f"{len(odds)} entrées extraites vers {dest}")
          PY

      - name: Diff H-5
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('55 15 * * *', github.event.schedule))
        run: |
          python scripts/online_fetch_zeturf.py --mode diff --out data/diff/diff_drift.json

      
      - name: Contrôle identifiants
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('55 15 * * *', github.event.schedule))
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          from pipeline_run import compute_drift_dict

          h30_path = Path("data/h30/odds.json")
          h5_path = Path("data/h5/odds.json")
          partants_path = Path("data/h5/h5.json")

          for path in (h30_path, h5_path, partants_path):
              if not path.exists():
                  raise SystemExit(f"Fichier manquant: {path}")

          odds_h30 = json.loads(h30_path.read_text(encoding="utf-8"))
          odds_h5 = json.loads(h5_path.read_text(encoding="utf-8"))
          partants_data = json.loads(partants_path.read_text(encoding="utf-8"))

          partants = partants_data.get("runners", [])
          id2name = partants_data.get(
              "id2name",
              {
                  str(p.get("id")): p.get("name", str(p.get("id")))
                  for p in partants
                  if p.get("id") is not None
              },
          )

          drift = compute_drift_dict(
              odds_h30,
              odds_h5,
              id2name,
              top_n=int(os.getenv("DRIFT_TOP_N", "5")),
              min_delta=float(os.getenv("DRIFT_MIN_DELTA", "0.8")),
          )

          print("IDs drift:", [row["id"] for row in drift.get("drift", [])])
          ticket_ids = [
              str(p.get("id"))
              for p in partants
              if p.get("id") is not None and str(p.get("id")) in odds_h5
          ]
          print("IDs tickets:", ticket_ids)

          missing = sorted(
              {
                  str(p.get("id"))
                  for p in partants
                  if p.get("id") is not None
              }
              - set(odds_h5)
          )
          if missing:
              print("::warning::Cotes manquantes pour:", ",".join(missing))
          else:
              print("Toutes les cotes H-5 sont présentes.")
          PY
      - name: Stats J/E Geny
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('55 15 * * *', github.event.schedule))
        env:
          GENY_COOKIE: ${{ secrets.GENY_COOKIE }}
        run: |
          python scripts/fetch_je_stats.py \
            --course-id "${{ steps.in.outputs.COURSE_ID }}" \
            --h5 data/h5/h5.json \
            --out data/h5/stats_je.json

      - name: Analyse H-5
        if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && contains('55 15 * * *', github.event.schedule))
        run: |
          extra_flags=""
          case "$ALLOW_JE_NA" in
            1|true|TRUE|True|yes|YES)
              extra_flags="--allow-je-na"
              ;;
          esac
          python pipeline_run.py analyse \
            --h30 data/h30/odds.json \
            --h5  data/h5/odds.json \
            --stats-je data/h5/stats_je.json \
            --partants data/h5/h5.json \
            --gpi config/gpi.yml \
            --outdir data/out \
            --budget=${BUDGET_TOTAL} \
            --ev-global=${EV_MIN_GLOBAL} \
            --roi-global=${ROI_MIN_GLOBAL} \
            --max-vol=${MAX_VOL_PAR_CHEVAL} \
            --min-payout=${MIN_PAYOUT_COMBOS} \
            $extra_flags


      - name: Tests unitaires essentiels
        run: pytest -q

      - name: Upload artefacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gpi_v51_${{ github.run_id }}
          path: |
            data/h30/**
            data/h5/**
            data/diff/**
            data/out/**
