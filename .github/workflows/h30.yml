name: Planning H-30 (artifacts)

on:
  workflow_dispatch:
  schedule:
    - cron: "30 7 * * *"  # 08:30 Paris

permissions:
  contents: read
  actions: write

env:
  PYTHONUTF8: "1"
  TZ: "Europe/Paris"
  OUTPUT_DIR: out/h30
  EXCEL_PATH: out/h30/planning.xlsx

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Lint sources.txt
        run: |
          python scripts/lint_sources.py --file sources.txt --enforce-today --warn-only || true

      - name: Fetch H-30 snapshots
        run: |
          set -euo pipefail
          if [ ! -f sources.txt ]; then
            echo "::error::sources.txt introuvable à la racine du dépôt" >&2
            exit 1
          fi
          mkdir -p "${OUTPUT_DIR}"
          while IFS= read -r raw_url; do
            url="$(printf '%s' "${raw_url}" | sed 's/#.*$//' | xargs)"
            if [ -z "${url}" ]; then
              continue
            fi
            echo "→ Snapshot ${url}"
            python online_fetch_zeturf.py --reunion-url "${url}" --snapshot H-30 --out "${OUTPUT_DIR}"
          done < sources.txt

      - name: Mettre à jour l'onglet Planning (H-30)
        run: |
          set -euo pipefail
          excel_dir=$(dirname "${EXCEL_PATH}")
          mkdir -p "${excel_dir}"
          python scripts/update_excel_planning.py \
            --phase H30 \
            --in "${OUTPUT_DIR}" \
            --excel "${EXCEL_PATH}"

      - name: Upload Excel & données
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: h30-${{ github.run_id }}
          path: |
            ${{ env.OUTPUT_DIR }}/**
            ${{ env.EXCEL_PATH }}
          if-no-files-found: warn

      - name: Synchroniser sur le stockage (optionnel)
        if: success() && env.EXCEL_PATH != '' && vars.GCS_BUCKET != ''
        env:
          GCS_BUCKET: ${{ vars.GCS_BUCKET }}
          GCS_PREFIX: ${{ vars.GCS_PREFIX || '' }}
          GCS_SERVICE_KEY_B64: ${{ secrets.GCS_SERVICE_KEY_B64 || '' }}
        run: |
          set -euo pipefail
          dir=$(dirname "${EXCEL_PATH}")
          python scripts/drive_sync.py --push "${dir}"
.github/workflows/h5.yml
Nouveau
+137
-0

name: Planning H-5 (artifacts)

on:
  workflow_dispatch:
  repository_dispatch:
    types: [hminus5]
  schedule:
    - cron: "*/5 8-20 * * *"  # toutes les 5 min (08:00-20:55 UTC)

permissions:
  contents: write
  actions: write

env:
  PYTHONUTF8: "1"
  TZ: "Europe/Paris"
  OUTPUT_DIR: out/hminus5
  EXCEL_PATH: out/hminus5/planning.xlsx

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Déclencher les analyses H-5 attendues
        env:
          RUNNER_SNAP_DIR: ${{ env.OUTPUT_DIR }}/snapshots
          RUNNER_ANALYSIS_DIR: ${{ env.OUTPUT_DIR }}/analysis
          RUNNER_OUTPUT_DIR: ${{ env.OUTPUT_DIR }}
        run: |
          set -euo pipefail
          mkdir -p "${RUNNER_SNAP_DIR}" "${RUNNER_ANALYSIS_DIR}"
          python scripts/cron_decider.py --meetings config/meetings.json

      - name: Mettre à jour l'onglet Planning (H-5)
        run: |
          set -euo pipefail
          excel_dir=$(dirname "${EXCEL_PATH}")
          mkdir -p "${excel_dir}"
          latest_dir=$(find "${OUTPUT_DIR}" -maxdepth 1 -type d -name 'R*C*' | sort | tail -n1)
          if [ -z "${latest_dir}" ]; then
            echo "::warning::Aucune analyse H-5 trouvée dans ${OUTPUT_DIR}."
            exit 0
          fi
          echo "Mise à jour basée sur ${latest_dir}"
          python scripts/update_excel_planning.py \
            --phase H5 \
            --in "${latest_dir}" \
            --excel "${EXCEL_PATH}"

      - name: Upload Excel & rapports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: h5-${{ github.run_id }}
          path: |
            ${{ env.OUTPUT_DIR }}/**
            ${{ env.EXCEL_PATH }}
          if-no-files-found: warn

      - name: Synchroniser sur le stockage (optionnel)
        if: success() && env.EXCEL_PATH != '' && vars.GCS_BUCKET != ''
        env:
          GCS_BUCKET: ${{ vars.GCS_BUCKET }}
          GCS_PREFIX: ${{ vars.GCS_PREFIX || '' }}
          GCS_SERVICE_KEY_B64: ${{ secrets.GCS_SERVICE_KEY_B64 || '' }}
        run: |
          set -euo pipefail
          dir=$(dirname "${EXCEL_PATH}")
          python scripts/drive_sync.py --push "${dir}"

      - name: Alerte Slack (échec)
        if: failure() && secrets.SLACK_WEBHOOK != ''
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        run: |
          python - <<'PY'
import json
import os
import urllib.request

webhook = os.environ["SLACK_WEBHOOK"]
text = "❌ Workflow {workflow} #{run} en échec sur {ref}".format(
    workflow=os.environ.get("GITHUB_WORKFLOW", "H-5"),
    run=os.environ.get("GITHUB_RUN_NUMBER", "?"),
    ref=os.environ.get("GITHUB_REF_NAME", os.environ.get("GITHUB_REF", "")),
)
url = f"https://github.com/{os.environ.get('GITHUB_REPOSITORY', '')}/actions/runs/{os.environ.get('GITHUB_RUN_ID', '')}"
payload = {
    "text": text,
    "blocks": [
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"❌ *{text}*\n<${url}|Voir le job>"
            },
        }
    ],
}
req = urllib.request.Request(
    webhook,
    data=json.dumps(payload).encode("utf-8"),
    headers={"Content-Type": "application/json"},
)
with urllib.request.urlopen(req) as resp:
    resp.read()
PY

      - name: Alerte email (échec)
        if: failure() && secrets.MAIL_SERVER != '' && secrets.MAIL_USERNAME != '' && secrets.MAIL_PASSWORD != '' && secrets.MAIL_TO != ''
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: ${{ secrets.MAIL_SERVER }}
          server_port: ${{ secrets.MAIL_PORT || '465' }}
          username: ${{ secrets.MAIL_USERNAME }}
          password: ${{ secrets.MAIL_PASSWORD }}
          subject: "❌ Workflow H-5 en échec"
          to: ${{ secrets.MAIL_TO }}
          from: ${{ secrets.MAIL_FROM || secrets.MAIL_USERNAME }}
          secure: true
          body: |
            Le workflow ${{ github.workflow }} (run ${{ github.run_number }}) a échoué.
            Détails: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
scripts/lint_sources.py
Nouveau
+163
-0

"""Basic linting utilities for validating daily ZEturf source URLs."""

from __future__ import annotations

import argparse
import datetime as dt
import sys
from pathlib import Path
from typing import Iterable
from urllib.parse import urlparse

try:  # Python 3.9+
    from zoneinfo import ZoneInfo
except Exception:  # pragma: no cover - Python <3.9 fallback
    ZoneInfo = None  # type: ignore[misc]

PARIS_TZ = ZoneInfo("Europe/Paris") if ZoneInfo is not None else None
DEFAULT_DOMAINS = ("zeturf.fr", "www.zeturf.fr")


class LintResult:
    """Container used to aggregate linting diagnostics."""

    __slots__ = ("errors", "warnings")

    def __init__(self) -> None:
        self.errors: list[str] = []
        self.warnings: list[str] = []

    def record_error(self, message: str) -> None:
        self.errors.append(message)

    def record_warning(self, message: str) -> None:
        self.warnings.append(message)

    def has_errors(self) -> bool:
        return bool(self.errors)

    def has_warnings(self) -> bool:
        return bool(self.warnings)

    def exit_code(self, warn_only: bool) -> int:
        if self.has_errors():
            return 2 if warn_only else 1
        if warn_only and self.has_warnings():
            return 2
        return 0


def _iter_urls(path: Path) -> Iterable[tuple[int, str]]:
    for idx, raw in enumerate(path.read_text(encoding="utf-8").splitlines(), start=1):
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        yield idx, line


def _validate_url(url: str, *, domains: tuple[str, ...]) -> tuple[str | None, str | None]:
    parsed = urlparse(url)
    if parsed.scheme not in {"http", "https"}:
        return None, "Schéma invalide (attendu http/https)."
    if not parsed.netloc:
        return None, "Nom de domaine manquant."
    host = parsed.netloc.lower()
    if not any(host == domain or host.endswith(f".{domain}") for domain in domains):
        return host, "Domaine inattendu."
    return host, None


def _today_slug() -> str:
    tz = PARIS_TZ or dt.timezone.utc
    return dt.datetime.now(tz).strftime("%Y-%m-%d")


def lint_file(
    file_path: Path,
    *,
    enforce_today: bool,
    warn_only: bool,
    domains: tuple[str, ...] = DEFAULT_DOMAINS,
) -> LintResult:
    result = LintResult()
    if not file_path.exists():
        result.record_error(f"Fichier introuvable: {file_path}")
        return result

    seen: dict[str, int] = {}
    today_slug = _today_slug()

    for line_no, url in _iter_urls(file_path):
        _, error = _validate_url(url, domains=domains)
        if error:
            result.record_error(f"Ligne {line_no}: {error} → {url}")
            continue
        previous = seen.get(url)
        if previous is not None:
            result.record_error(
                f"Ligne {line_no}: duplication détectée (également ligne {previous})."
            )
            continue
        seen[url] = line_no
        if enforce_today and today_slug not in url:
            result.record_warning(
                f"Ligne {line_no}: la date du jour ({today_slug}) est absente de l'URL."
            )

    if not seen:
        result.record_warning("Aucune URL active détectée dans le fichier.")

    return result


def _build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Lint de sources.txt (URLs ZEturf)")
    parser.add_argument("--file", required=True, help="Chemin vers sources.txt")
    parser.add_argument(
        "--enforce-today",
        action="store_true",
        help="Signale les URLs qui ne contiennent pas la date du jour.",
    )
    parser.add_argument(
        "--domain",
        dest="domains",
        action="append",
        help="Domaine attendu (par défaut: zeturf.fr). Peut être répété.",
    )
    parser.add_argument(
        "--warn-only",
        action="store_true",
        help="Ne retourne pas un code d'échec en présence d'erreurs (code 2).",
    )
    return parser


def main(argv: list[str] | None = None) -> int:
    parser = _build_parser()
    args = parser.parse_args(argv)

    domains: tuple[str, ...]
    if args.domains:
        domains = tuple(domain.lower() for domain in args.domains if domain)
    else:
        domains = DEFAULT_DOMAINS

    file_path = Path(args.file)
    result = lint_file(
        file_path,
        enforce_today=args.enforce_today,
        warn_only=args.warn_only,
        domains=domains,
    )

    for message in result.errors:
        print(f"::error::{message}")
    for message in result.warnings:
        level = "warning" if args.warn_only else "notice"
        print(f"::{level}::{message}")

    return result.exit_code(args.warn_only)


if __name__ == "__main__":  # pragma: no cover
    sys.exit(main())
