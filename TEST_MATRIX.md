# Matrice de Tests - Hippique Orchestrator

Ce document dresse l'inventaire des composants du système, les risques associés, et les stratégies de test pour assurer la qualité avant la mise en production.

| Composant | Risque Fonctionnel | Tests Existants (Couverture) | Tests Manquants | KPI Cible | Effort | Priorité |
| :--- | :--- | :--- | :--- | :--- | :--- | :---: |
| **Gestion de l'environnement** (`config/env_utils.py`) | **Critique**. Une mauvaise configuration peut empêcher le démarrage ou entraîner un comportement erroné en production. | Tests unitaires robustes (96%) vérifiant les valeurs par défaut, les alias, le "fail-fast" et le casting. | - Aucun test majeur manquant. | > 95% | Faible | **Faible** |
| **Scripts autonomes** (`scripts/*`) | **Élevé**. Nombreux scripts avec une logique métier non testée. Risque de crash ou de corruption de données lors des exécutions manuelles ou via CI/CD. | Très faible couverture générale (0-60%). Seuls quelques scripts ont des tests basiques. | - Tests unitaires pour la logique principale de chaque script critique (ex: `online_fetch_zeturf`, `update_excel`).<br>- Tests d'intégration simulant l'exécution via `CliRunner` avec différents arguments. | > 70% pour les scripts critiques | Élevé | **Élevée** |
| **Logging** (`logging_io.py`) | **Élevé**. Un logging défaillant en production peut masquer des erreurs, rendant le débogage et le monitoring impossibles. | Couverture très faible (47%). Seuls les aspects basiques sont touchés. | - Tests spécifiques vérifiant que les messages de log critiques sont bien formatés et émis.<br>- Test du mécanisme de rotation/archivage si applicable. | > 85% | Moyen | **Élevée** |
| **Persistance (Firestore)** (`firestore_client.py`) | **Moyen**. Composant I/O critique. Les erreurs de connexion ou les formats de données inattendus peuvent causer des pertes de données. | Bonne couverture (80%). Les cas nominaux (CRUD) sont testés. | - Tests des cas limites : collection vide, document non trouvé, gestion des erreurs de connexion/permission (via mocks). | > 90% | Moyen | **Moyenne** |
| **API Publique** (`/api/pronostics`, `/pronostics`) | **Moyen**. Point d'entrée principal pour les utilisateurs. Un bug peut dégrader l'expérience utilisateur et la confiance. | Tests d'intégration avec `TestClient` (200, 304, 422). Validation du schéma de base et du rendu HTML. | - Test d'intégration avec un plan de courses vide (`daily_plan: []`).<br>- Test de robustesse du schéma de réponse avec des données partielles ou malformées. | 100% des endpoints couverts par des tests d'intégration. | Faible | **Moyenne** |
| **Endpoints Sensibles** (`/schedule`, `/ops/*`, `/tasks/*`) | **Critique**. Actions à privilèges élevés. Un accès non autorisé peut déclencher des opérations coûteuses ou modifier l'état du système. | Tests de sécurité robustes (401/403 sans authentification, 200 avec). La logique de base est couverte. | - Smoke test `prod-like` pour valider l'authentification avec une vraie clé API (via variable d'env). | 100% des cas d'authentification testés. | Faible | **Moyenne** |
| **Pipeline d'Analyse** (`analysis_pipeline.py`, `pipeline_run.py`) | **Faible**. Cœur de la logique métier, mais déjà très bien couvert par les tests. Le risque résiduel est faible. | Couverture excellente (>95%). De nombreux cas nominaux et limites sont déjà testés. | - Tests supplémentaires sur les branches non couvertes identifiées (cas très rares). | > 98% | Faible | **Faible** |
| **Scrapers** (`scrapers/*`) | **Faible**. Bien isolés et testés avec des fixtures HTML locales. Le risque principal (changement de structure du site web) est géré. | Excellente couverture (>95%). Le parsing est validé sur des exemples réels. | - Mettre en place un protocole "canary" (monitoring) documenté pour détecter les changements de structure des sites web en production. | > 95% | Faible | **Faible** |
| **Scheduler** (`scheduler.py`) | **Faible**. Logique de planification des tâches bien testée, y compris les cas limites (tâches dans le passé, mode `force`). | Couverture complète (100%). | - Aucun test majeur manquant. | > 95% | Faible | **Faible** |

**Légende :**
- **KPI Cible** : Métrique de succès pour la couverture ou la complétude des tests.
- **Effort** : Estimation de la complexité pour implémenter les tests manquants.
- **Priorité** : Ordre dans lequel les tests doivent être développés pour réduire les risques les plus importants.
