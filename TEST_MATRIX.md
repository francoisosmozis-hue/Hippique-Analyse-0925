# Matrice de Tests - Hippique Orchestrator

Ce document détaille la stratégie de test pour chaque composant majeur du projet, en identifiant les risques, les tests existants, les tests manquants et les indicateurs de succès.

| Composant | Risque | Tests Existants (Couverture) | Tests Manquants | KPI de Qualité | Effort | Priorité |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **API Publique (`/api/pronostics`)** | Moyen | `test_api_endpoints.py` (validation schéma, ETag, date) | - Test de charge/stress (non-scope) <br>- Test de performance (latence < 1s) <br>- Scénario "aucune course trouvée" vs "scraping échoué" | Stabilité schéma JSON (100% validation), Taux erreur < 0.1% | Faible | Moyenne |
| **UI (`/pronostics`)** | Faible | `test_api_endpoints.py` (rendu HTML basique) | - Test de l'appel JS à l'API (via mock) <br>- Validation de l'affichage des données API | Le marqueur `data-api-endpoint` est présent et correct | Faible | Faible |
| **Endpoints Sécurisés (`/schedule`, `/ops/*`)** | **Élevé** | `test_api_security.py` (mocks pour API Key/OIDC) | - **Test d'intégration (smoke test) avec une vraie clé API via env var** <br>- Test du mode `REQUIRE_AUTH=false` pour tous les endpoints | 401/403 si auth échoue (100%), 200 si succès | Moyen | **Élevée** |
| **Pipeline d'Analyse (`pipeline_run.py`)** | **Élevé** | `test_pipeline_run.py` (80%) | - Cas limites (ex: `runners` vide, `partants` invalide) <br>- Comportement avec calibration ROI manquante/invalide <br>- Tests des portes de sécurité (overround, EV) avec données extrêmes | Couverture > 85% <br> 0 régression sur les cas nominaux | Moyen | **Élevée** |
| **Validateur EV (`validator_ev.py`)** | **Critique** | `test_validator_ev.py` (59%) | - Validation de chaque "gate" (budget, JE stats) <br>- Test des cas où les données `je_feature` sont absentes <br>- Scénarios avec des cotes invalides ou manquantes | Couverture > 80% <br> Scénarios de rejet documentés et testés | **Élevé** | **Critique** |
| **Persistance (Firestore/GCS)** | Faible | `test_firestore_client.py` (100%), `test_gcs_client.py` (75%) | - Test du format `doc_id` pour tous les cas <br>- Comportement sur collection vide/inexistante pour `get_races_for_date` | Couverture `gcs_client.py` > 85% | Faible | Moyenne |
| **Scrapers (Boturfers, Geny, ZoneTurf)** | **Élevé** | `test_scraper_*.py` (parsing via fixtures HTML) | - **Ajouter des fixtures HTML pour les cas d'erreur** (page 404, structure modifiée, données manquantes) <br>- Test de résilience (ex: une course mal formée ne doit pas bloquer tout le programme) <br>- Protocole de monitoring "canary" (alerte si la structure change) | Couverture > 90% sur `stats_provider.py` | Moyen | **Élevée** |
| **Scheduler (`scheduler.py`)** | Moyen | `test_scheduler.py` (100%, mock Cloud Tasks) | - Test du comportement si le plan de course est vide <br>- Test de la gestion des fuseaux horaires (calcul de l'heure de planification) | 0 tâche créée si plan vide, heures UTC correctes | Faible | Faible |
| **Gestion de l'Environnement (`env_utils.py`)** | **Élevé** | `test_env_utils.py` (96%) | - **Ajouter un test pour le mode "fail-fast" en prod** si une variable requise est manquante | Le service ne démarre pas en prod si `REQUIRED` var manque | Faible | Moyenne |