# Analyse Hippique â€“ GPI v5.1 (Budget 5â‚¬ / EV+)

Pipeline **pro** pour planifier, capturer Hâ€‘30 / Hâ€‘5, analyser et consigner chaque course (tickets, EV/ROI, pastille verte/rouge) avec export Google Cloud Storage + mise Ã  jour Excel.

---

## ğŸ” Vue dâ€™ensemble

- **09:00 Paris** : gÃ©nÃ©ration du **planning du jour** (rÃ©unions, courses, horaires, URLs).
- **Scheduler (*/5 min)** : dÃ©clenche auto les fenÃªtres **Hâ€‘30** (snapshots cotes + stats) et **Hâ€‘5** (analyse GPI v5.1 + tickets).
- **Postâ€‘results (*/15 min)** : rÃ©cupÃ©ration **arrivÃ©es officielles**, **mise Ã  jour Excel** (ROI rÃ©el), **upload GCS**.

**Standards verrouillÃ©s** (GPI v5.1) :
- Budget **max 5 â‚¬** / course, **2 tickets max** (SP + 1 combinÃ© Ã©ventuel, configurable via `MAX_TICKETS_SP`).
- **EV globale â‰¥ +35 %** et **ROI estimÃ© global â‰¥ +25 %** (**ROI SP â‰¥ +10 %**) pour valider le **vert**.
- CombinÃ©s uniquement si **payout attendu > 12 â‚¬** (calibration).
- **KELLY_FRACTION = 0.5** : moitiÃ© de Kelly pour rÃ©duire la variance au prix d'une EV moindre; cap 60 % par cheval.
- **MIN_STAKE_SP = 0.10** : mise minimale par ticket SP, Ã©vite les micro-mises (rÃ©duit variance) mais peut bloquer un peu d'EV.
- **ROUND_TO_SP = 0.10** : arrondi des mises SP Ã  0,10 â‚¬; utiliser `0` pour dÃ©sactiver l'arrondi sans provoquer de crash tout en conservant le calcul EV/ROI.
- **SHARPE_MIN = 0.5** : seuil minimal de ratio EV/Ïƒ; filtre les paris Ã  variance trop Ã©levÃ©e.

### Garde-fous opÃ©rationnels

- `online_fetch_zeturf.fetch_race_snapshot()` expose l'API de snapshot Python attendue par `runner_chain`. Elle parcourt dÃ©sormais directement la page publique ZEturf d'une course (ou bascule sur le cache local via `use_cache=True`) puis retourne uniquement les blocs `runners`, `partants`, `market` et `phase` attendus par les consommateurs CLI.
- La phase **Hâ€‘5** rÃ©essaie automatiquement les collectes `JE`/`chronos` en cas d'absence des CSV, marque la course Â« non jouable Â» via `UNPLAYABLE.txt` si la rÃ©gÃ©nÃ©ration Ã©choue et Ã©vite ainsi que le pipeline plante.
- Les combinÃ©s sont dÃ©sormais filtrÃ©s strictement dans `pipeline_run.py` : statut `"ok"` obligatoire, EV â‰¥ +40 % et payout attendu â‰¥ 10 â‚¬ sans heuristique. Le runner et le pipeline partagent la mÃªme rÃ¨gle, ce qui garantit un comportement homogÃ¨ne en CLI comme dans les automatisations.
- Le seuil d'overround est adaptÃ© automatiquement (`1.30` standard dÃ©sormais alignÃ© sur la garde ROI, `1.25` pour les handicaps plats ouverts â‰¥ 14 partants) pour rÃ©duire les tickets exotiques Ã  faible espÃ©rance.

### API `/analyse`

L'API FastAPI expose un endpoint `POST /analyse` (voir `main.py`).

- Le champ optionnel `course_url` permet de transmettre une URL de rÃ©union Ã  scraper.
- Seules les URLs en **HTTPS** et dont le domaine appartient Ã  la liste blanche `zeturf.fr` / `geny.com` (y compris sous-domaines) sont acceptÃ©es.
- Toute URL hors de cette liste retourne une erreur **422** avec un message explicite.

---

## ğŸ—‚ï¸ Arborescence

```
analyse-hippique/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ .env.example
â”œâ”€ gpi_v51.yml
â”œâ”€ calibration/
â”‚  â”œâ”€ payout_calibration.yaml
â”‚  â”œâ”€ probabilities.yaml
â”‚  â””â”€ calibrate_simulator.py
â”œâ”€ config/
â”‚  â”œâ”€ sources.yml
â”‚  â””â”€ meetings.json    # exemple de planning (reunion/course/time)
â”œâ”€ data/
â”‚  â”œâ”€ planning/          # programmes du jour (JSON)
â”‚  â”œâ”€ snapshots/         # H-30 / H-5 (cotes + stats)
â”‚  â”œâ”€ analyses/          # analyses H-5 (tickets + pastille)
â”‚  â””â”€ results/           # arrivÃ©es + exports Excel/CSV
â”œâ”€ excel/
â”‚  â””â”€ modele_suivi_courses_hippiques.xlsx
â”œâ”€ scripts/
â”‚  â”œâ”€ runner_chain.py
â”‚  â”œâ”€ fetch_schedule.py
â”‚  â”œâ”€ pipeline_run.py
â”‚  â”œâ”€ simulate_ev.py
â”‚  â”œâ”€ simulate_wrapper.py
â”‚  â”œâ”€ validator_ev.py (ou validator_ev_v2.py)
â”‚  â”œâ”€ online_fetch_zeturf.py
â”‚  â”œâ”€ fetch_je_stats.py
â”‚  â”œâ”€ fetch_je_chrono.py
â”‚  â”œâ”€ p_finale_export.py
â”‚  â”œâ”€ get_arrivee_geny.py
â”‚  â”œâ”€ update_excel_with_results.py
â”‚  â””â”€ drive_sync.py
â””â”€ .github/workflows/
   â”œâ”€ daily_planning.yml
   â”œâ”€ race_scheduler.yml
   â””â”€ post_results.yml
```

### Configuration des sources

Le fichier `config/sources.yml` pointe vers l'API de snapshot Zeturf :

```yaml
zeturf:
  url: "https://www.zeturf.fr/rest/api/race/{course_id}"
```

Remplacez `{course_id}` par l'identifiant numÃ©rique de la course avant d'appeler
`scripts/online_fetch_zeturf.py --mode h30` ou `--mode h5`.
Le workflow `gpi_v51.yml` fait cette substitution automatiquement via son entrÃ©e
`course_id`. Pour un test localâ€¯:

```bash
COURSE_ID=123456 sed -i "s/{course_id}/$COURSE_ID/" config/sources.yml
python scripts/online_fetch_zeturf.py --mode h30 --out data/h30/h30.json
```

### DÃ©tection robuste de l'heure de dÃ©part

`scripts/online_fetch_zeturf.py` rÃ©cupÃ¨re dÃ©sormais l'heure officielle de dÃ©part
des courses directement depuis la page publique ZEturf lorsque l'API ne la
fournit pas. Le scraper :

- parcourt les balises `<time>` et les attributs structurÃ©s (`data-start-time`,
  `datetime`, etc.) ;
- lit les blocs `application/ld+json` pour capturer les champs `startDate` ou
  `startTime` ;
- applique en dernier ressort une expression rÃ©guliÃ¨re tolÃ©rante (`21 h 05`,
  `21h05`, `21.05`...).

Les heures sont normalisÃ©es au format `HH:MM` avant d'Ãªtre injectÃ©es dans les
snapshots (`meta.start_time` et `start_time`). Cela garantit que le script
`update_excel_planning.py` dispose toujours d'une heure fiable pour l'onglet
Planning.

### Mise Ã  jour automatisÃ©e du planning Excel

Le script `scripts/update_excel_planning.py` met Ã  jour l'onglet **Planning**
du classeur `modele_suivi_courses_hippiques.xlsx` Ã  partir des snapshots Hâ€‘30
et des analyses Hâ€‘5.

Commandes usuelles :

- **Phase Hâ€‘30** â€“ traite un rÃ©pertoire contenant les snapshots collectÃ©s :

  ```bash
  python scripts/update_excel_planning.py \
    --phase H30 \
    --in data/meeting \
    --excel modele_suivi_courses_hippiques.xlsx
  ```

- **Phase Hâ€‘5** â€“ injecte l'analyse d'une course (tickets, statut, jouable) :

  ```bash
  python scripts/update_excel_planning.py \
    --phase H5 \
    --in data/R4C5 \
    --excel modele_suivi_courses_hippiques.xlsx
  ```

- **VÃ©rifier la jouabilitÃ© d'une course** â€“ rÃ©utilise le pipeline de garde-fous
  `runner_chain` et affiche Ã  la fois le JSON complet et un verdict lisible :

  ```bash
  python tools/check_course_playable.py --dir data/R4C5
  ```

  Les paramÃ¨tres de garde (`--budget`, `--overround-max`, `--ev-min-exotic`,
  etc.) sont identiques Ã  ceux du CLI principal et permettent d'ajuster les
  seuils lors des vÃ©rifications ponctuelles.

Le script crÃ©e l'onglet s'il est absent, garantit la prÃ©sence des colonnes
standard (Date, RÃ©union, Course, Hippodrome, Heure, Partants, Discipline,
Statuts Hâ€‘30/Hâ€‘5, Jouable Hâ€‘5, Tickets Hâ€‘5, Commentaires) et rÃ©alise une mise
Ã  jour en **upsert** sur la clÃ© `(Date, RÃ©union, Course)` pour Ã©viter les
doublons. Les commandes ciâ€‘dessus peuvent Ãªtre enchaÃ®nÃ©es avec un utilitaire
d'upload (ex. `scripts/drive_sync.py`) pour pousser le fichier sur Google
Drive.

### Automatisation GitHub Actions Hâ€‘30 / Hâ€‘5

Deux workflows dÃ©diÃ©s (`.github/workflows/h30.yml` et `.github/workflows/h5.yml`)
permettent d'orchestrer la collecte et l'analyse quotidiennes Ã  partir du
fichier `sources.txt` :

- **08:30 Europe/Paris** â†’ workflow *Planning H-30* :
  - lance `online_fetch_zeturf.py` pour chaque rÃ©union listÃ©e ;
  - met Ã  jour l'onglet Planning (phase `H30`) via
    `scripts/update_excel_planning.py` ;
  - publie les snapshots + l'Excel consolidÃ© en tant qu'artifact GitHub Actions
    (et peut synchroniser vers GCS si les variables `GCS_*` sont dÃ©finies).
- **Toutes les 5 minutes (08:00â€“20:55 UTC)** â†’ workflow *Planning H-5* :
  - dÃ©clenche `scripts/cron_decider.py` pour identifier les courses Ã  Hâ€‘5 ;
  - actualise l'onglet Planning (phase `H5`) Ã  partir de la derniÃ¨re analyse ;
  - uploade les rapports en artifact et propose la mÃªme synchronisation GCS.

Un linter dÃ©diÃ© (`scripts/lint_sources.py`) est exÃ©cutÃ© automatiquement en Hâ€‘30
avec `--enforce-today --warn-only` pour dÃ©tecter :

- URLs manquantes, mal formÃ©es ou hors domaine `zeturf.fr` ;
- doublons ;
- absence de la date du jour dans les liens renseignÃ©s.

Le job crÃ©e un commentaire GitHub en cas d'anomalie et alerte Slack si le
secret `SLACK_WEBHOOK` est dÃ©fini. Pour transformer ces avertissements en
Ã©checs bloquants, retirer `--warn-only` dans l'Ã©tape Â« Lint sources.txt Â».

Le workflow Hâ€‘5 propage Ã©galement les erreurs vers Slack et peut envoyer un
email (via `dawidd6/action-send-mail`) lorsque les secrets `MAIL_*` sont
configurÃ©s. Pour tester localement la qualitÃ© des sources avant un commit :

```bash
python scripts/lint_sources.py --file sources.txt --enforce-today
```

#### Exemple de flux quotidien

1. **Collecte Hâ€‘30**
   - Renseigner `sources.txt` avec une URL ZEturf par rÃ©union.
   - ExÃ©cuter la boucle de snapshots :

     ```bash
     export TZ=Europe/Paris
     while read -r url; do
       python online_fetch_zeturf.py --reunion-url "$url" --snapshot H-30 --out data/meeting
     done < sources.txt
     ```

   - Mettre Ã  jour l'Excel :

     ```bash
     python scripts/update_excel_planning.py \
       --phase H30 \
       --in data/meeting \
       --excel modele_suivi_courses_hippiques.xlsx
     ```

2. **Analyse Hâ€‘5**
   - Lancer l'analyse (ex. `python analyse_courses_du_jour_enrichie.py`).
   - Actualiser l'onglet Planning avec la course traitÃ©e :

     ```bash
     python scripts/update_excel_planning.py \
       --phase H5 \
       --in data/R4C5 \
       --excel modele_suivi_courses_hippiques.xlsx
     ```

3. **Synchronisation Drive (optionnel)**
   - Utiliser l'outil existant pour pousser le fichier mis Ã  jour :

     ```bash
     python scripts/drive_sync.py \
       --push \
       --folder-id "<ID_DOSSIER_DRIVE>" \
       --credentials credentials.json \
       --file modele_suivi_courses_hippiques.xlsx
     ```

Cette sÃ©quence garantit que les colonnes Statut Hâ€‘30/Hâ€‘5, Jouable et Tickets
sont enrichies au fur et Ã  mesure des analyses tout en conservant un historique
cohÃ©rent pour le suivi quotidien.
---

## âš™ï¸ Installation locale

1) **Python 3.12+**
2) DÃ©pendances :
```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```
**Ex. de packages** : `pandas`, `openpyxl`, `pyyaml`, `requests`, `google-api-python-client`, `google-auth`, `google-auth-httplib2`, `google-auth-oauthlib` â€¦

> **SciPy facultatif** : si `scipy` n'est pas installÃ©, `optimize_stake_allocation` utilisera un optimiseur de secours plus simple.

3) Variables locales : dupliquez `.env.example` en `.env` et ajustez si besoin.

Variables disponibles :

| Variable | DÃ©faut | Description |
| --- | --- | --- |
| `ALLOW_HEURISTIC` | `0` | dÃ©sactive les heuristiques de backup (`1` pour les autoriser). |

Afin de tester localement ou en CI, un fichier d'exemple `config/meetings.json`
illustre le format attendu (`reunion`, `course`, `time`).
Un planning rÃ©el peut Ãªtre gÃ©nÃ©rÃ© via `python scripts/fetch_schedule.py --out config/meetings.json`.

---

## ğŸ” Secrets & Variables GitHub

Dans **Settings â†’ Secrets and variables â†’ Actions** du repo, crÃ©er :

**Secrets**
- `GCS_SERVICE_KEY_B64` â†’ clÃ© de service Google Cloud encodÃ©e en base64 (`credentials.json`)
- `ZETURF_LOGIN` â†’ identifiant pour la connexion Zeturf
- `ZETURF_PASSWORD` â†’ mot de passe pour la connexion Zeturf
- `PYPI_EXTRA_INDEX` *(optionnel)* â†’ URL d'un dÃ©pÃ´t PyPI privÃ©
- `GENY_COOKIE` *(optionnel)* â†’ cookie d'accÃ¨s pour rÃ©cupÃ©rer les donnÃ©es Geny

**Variables**
- `GCS_BUCKET` â†’ bucket Google Cloud Storage de destination
- `GCS_PREFIX` *(optionnel)* â†’ prÃ©fixe appliquÃ© aux objets uploadÃ©s (ex: `hippiques/prod`)
- `GOOGLE_CLOUD_PROJECT` *(optionnel)* â†’ projet GCP utilisÃ© pour l'authentification
- `MEETING_URLS` â†’ rÃ©unions du jour pour Hâ€‘30
- `COURSES_URLS` â†’ cours supplÃ©mentaires pour Hâ€‘5

> âš ï¸ **SÃ©curitÃ© :** ne commitez jamais `credentials.json` ni la valeur de ces secrets et Ã©vitez toute fuite (logs, issues, captures d'Ã©cran).

---

## ğŸ§° Workflows GitHub

### 1) `daily_planning.yml` â€” 09:00 Paris
- Appelle `scripts/online_fetch_zeturf.py --mode planning`
- Ã‰crit `data/planning/YYYY-MM-DD.json`

### 2) `race_scheduler.yml` â€” toutes les 5 min
- Appelle `scripts/runner_chain.py` avec fenÃªtres **Hâ€‘30** puis **Hâ€‘5**.
- **Hâ€‘30** : snapshots cotes + stats (JSON).  
-- **Hâ€‘5** : enrichissement J/E + chronos (si dispo) â†’ **pipeline** (tickets, EV/ROI) â†’ **pastille** (VERT/ROUGE) â†’ export JSON/CSV â†’ **upload GCS**.

### 3) `post_results.yml` â€” toutes les 15 min
- `get_arrivee_geny.py` â†’ `data/results/ARRIVEES.json`
- `update_excel_with_results.py` â†’ met Ã  jour `excel/modele_suivi_courses_hippiques.xlsx`
- Upload Excel + rÃ©sultats sur GCS

### ğŸ§¾ Mise Ã  jour de l'onglet Â«â€¯Planningâ€¯Â»

Le script `scripts/update_excel_planning.py` assure l'upsert des lignes **Hâ€‘30** et **Hâ€‘5** dans le classeur `modele_suivi_courses_hippiques.xlsx`.

1. **Snap Hâ€‘30** â€“ toutes les rÃ©unions franÃ§aises du jour :

   ```bash
   export TZ=Europe/Paris
   while read -r URL; do
     python online_fetch_zeturf.py --reunion-url "$URL" --snapshot H-30 --out data/meeting
   done < sources.txt

   python scripts/update_excel_planning.py \
     --phase H30 \
     --in data/meeting \
     --excel modele_suivi_courses_hippiques.xlsx
   ```

   Le script crÃ©e l'onglet Â«â€¯Planningâ€¯Â» s'il est absent, alimente les colonnes *Date*, *RÃ©union*, *Course*, *Hippodrome*, *Heure*, *Partants*, *Discipline* et positionne Â«â€¯CollectÃ©â€¯Â» dans *Statut Hâ€‘30*.

2. **Snap Hâ€‘5** â€“ par course analysÃ©e :

   ```bash
   python scripts/update_excel_planning.py \
     --phase H5 \
     --in data/R4C5 \
     --excel modele_suivi_courses_hippiques.xlsx
   ```

   La ligne ciblÃ©e est mise Ã  jour avec *Statut Hâ€‘5 = AnalysÃ©*, le drapeau *Jouable Hâ€‘5* (Oui/Non selon `abstain`) et une synthÃ¨se compacte des tickets (*Tickets Hâ€‘5*). Les colonnes vides sont conservÃ©es pour d'Ã©ventuels commentaires manuels.
   Le libellÃ© du statut Hâ€‘5 peut Ãªtre personnalisÃ© via l'option `--status-h5` (ex. `--status-h5 "ValidÃ©"`).

### Lancer les workflows manuellement

Les trois workflows ci-dessus sont planifiÃ©s mais peuvent aussi Ãªtre dÃ©clenchÃ©s Ã  la demande depuis l'onglet **Actions** du dÃ©pÃ´t
via le bouton **Run workflow** ou en ligne de commandeâ€¯:

```bash
gh workflow run race_scheduler.yml
```

Les fichiers gÃ©nÃ©rÃ©s apparaissent ensuite sous `data/` et `excel/`.

### DÃ©clenchement via API

Un **Personal Access Token** (`GH_PAT`) disposant des scopes `repo` et `workflow` est requis.

#### Mode Hâ€‘30

```bash
curl -X POST \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer GH_PAT" \
  https://api.github.com/repos/OWNER/REPO/actions/workflows/hippique-pipeline.yml/dispatches \
  -d '{"ref":"main","inputs":{"mode":"h30","date":"YYYY-MM-DD","meeting":"R1","race":"C1","hippodrome":"PARIS-VINCENNES","discipline":"trot","course_id":"123456"}}'
```

#### Mode Hâ€‘5

```bash
curl -X POST \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer GH_PAT" \
  https://api.github.com/repos/OWNER/REPO/actions/workflows/hippique-pipeline.yml/dispatches \
  -d '{"ref":"main","inputs":{"mode":"h5","date":"YYYY-MM-DD","meeting":"R1","race":"C1","hippodrome":"PARIS-VINCENNES","discipline":"trot","course_id":"123456"}}'
```

#### Mode post-course

```bash
curl -X POST \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer GH_PAT" \
  https://api.github.com/repos/OWNER/REPO/actions/workflows/hippique-pipeline.yml/dispatches \
  -d '{"ref":"main","inputs":{"mode":"post","date":"YYYY-MM-DD","meeting":"R1","race":"C1","hippodrome":"PARIS-VINCENNES","discipline":"trot","course_id":"123456"}}'
```

> Rappel : `date` suit le format `YYYY-MM-DD`. Les champs `meeting` et `race` utilisent la notation `R#/C#` (ex. `R1`, `C5`) et `course_id` est l'identifiant numÃ©rique de la course.


### Alertes dans les fichiers de suivi

Chaque course analysÃ©e ajoute une ligne dans `data/RxCy/tracking.csv`. Si une colonne `ALERTE_VALUE` est prÃ©sente, le combinÃ©
associÃ© affiche un EV > 0.5 et un payout attendu > 20 â‚¬ et mÃ©rite une vÃ©rification manuelle.

### â˜ï¸ Synchronisation Google Cloud Storage

1. CrÃ©ez un **compte de service** dans la console Google Cloud et donnez-lui
   l'accÃ¨s en Ã©criture au bucket cible.
2. DÃ©finissez les variables d'environnement suivantes :
   - `GCS_BUCKET` (obligatoire) â†’ nom du bucket de destination ;
   - `GCS_SERVICE_KEY_B64` (obligatoire) â†’ contenu base64 du `credentials.json`
     du compte de service ;
   - `GCS_PREFIX` *(optionnel)* â†’ sous-dossier virtuel (prÃ©fixe) oÃ¹ ranger les
     artefacts ;
   - `GOOGLE_CLOUD_PROJECT` *(optionnel)* â†’ projet GCP pour journaliser les
     accÃ¨s.

Le module `scripts/drive_sync.py` expose `upload_file`, `download_file` et
`push_tree` basÃ©s sur `google-cloud-storage`.

```bash
python scripts/drive_sync.py \
  --upload-glob "data/results/**/*.json" \
  --upload-glob "excel/*.xlsx"
```

Plusieurs motifs `--upload-glob` peuvent Ãªtre fournis.  Pour tÃ©lÃ©charger un
objet : `python scripts/drive_sync.py --download chemin/objet.json destination.json`.

### RÃ©cupÃ©rer les donnÃ©es archivÃ©es

Pour rapatrier les fichiers `snapshot_*.json` et `analysis*.json` d'une date
prÃ©cise, utilisez :

```bash
export GCS_BUCKET="<bucket>"
export GCS_SERVICE_KEY_B64="$(base64 -w0 credentials.json)"
python scripts/restore_from_drive.py --date YYYY-MM-DD --dest dossier_sortie
```

Ajoutez Ã©ventuellement `GCS_PREFIX` pour cibler un sous-dossier. Les fichiers
correspondants sont tÃ©lÃ©chargÃ©s dans le dossier indiquÃ© par `--dest`.

---

## ğŸ§® RÃ¨gles EV/ROI (GPI v5.1)

| RÃ¨gle | Valeur |
|---|---|
| Budget max par course | **5 â‚¬** |
| Tickets max | **2** (SP + 1 combinÃ©) |
| Partage SP / CombinÃ©s | **60% / 40%** |
| Cap Kelly par cheval (`KELLY_FRACTION`) | **60 %** |
| EV globale (combinÃ©s) | **â‰¥ +35 %** |
| ROI estimÃ© SP | **â‰¥ +10 %** |
| ROI estimÃ© global | **â‰¥ +25 %** |
| Payout min combinÃ©s | **> 12 â‚¬** |
| Mise minimale SP (`MIN_STAKE_SP`) | **0.10 â‚¬** |
| Arrondi mise SP (`ROUND_TO_SP`) | **0.10 â‚¬** (`0` dÃ©sactive l'arrondi sans provoquer d'erreur) |
| Sharpe min (`SHARPE_MIN`) | **0.5** |
| Coefficient de drift des cotes (`DRIFT_COEF`) | **0.05** |
| Coefficient bonus J/E (`JE_BONUS_COEF`) | **0.001** |
| Pastille **VERT** si | EVâ‰¥35% & ROIâ‰¥25% & (si combinÃ©s) payout>12â‚¬ |

### Variables de configuration principales

| ClÃ© | Description |
| --- | --- |
| `BUDGET_TOTAL` | Budget maximum allouÃ© par course. |
| `SP_RATIO` | Part du budget dÃ©diÃ©e aux paris simples (SP). |
| `COMBO_RATIO` | Part du budget dÃ©diÃ©e aux combinÃ©s. |
| `EV_MIN_SP` | EV minimale requise pour les tickets SP (ratio du budget SP). |
| `EV_MIN_SP_HOMOGENEOUS` | Seuil EV SP appliquÃ© lorsque le champ est considÃ©rÃ© homogÃ¨ne. |
| `EV_MIN_GLOBAL` | EV minimale globale pour valider l'Ã©mission des combinÃ©s. |
| `ROI_MIN_SP` | ROI minimal attendu pour les tickets simples (10â€¯% par dÃ©faut). |
| `ROI_MIN_GLOBAL` | ROI minimal global attendu pour les combinÃ©s (25â€¯% par dÃ©faut). |
| `MAX_VOL_PAR_CHEVAL` | Fraction maximale du budget sur un seul cheval. |
| `MIN_PAYOUT_COMBOS` | Gain minimal attendu pour autoriser un ticket combinÃ© (12â€¯â‚¬ par dÃ©faut). |
| `EXOTIC_MIN_PAYOUT` | Alias de `MIN_PAYOUT_COMBOS` pour compatibilitÃ©. |
| `ALLOW_JE_NA` | Autorise l'absence de stats jockey/entraÃ®neur lors de l'analyse. |
| `SNAPSHOTS` | Phases de collecte des cotes pour le drift (ex. `H30,H5`). |
| `DRIFT_TOP_N` | Nombre maximal de steams/drifts conservÃ©s. |
| `DRIFT_MIN_DELTA` | Variation minimale de cote pour Ãªtre retenue comme drift/steam. |
| `P_TRUE_MIN_SAMPLES` | Historique minimal (Ã©chantillons/courses) pour activer le modÃ¨le `p_true`. |

> â„¹ï¸ Le pipeline accepte Ã©galement certains alias conviviaux : `TotalBudget`,
> `simpleShare`, `comboShare` ou `maxStakePerHorse` (et leurs Ã©quivalents en
> variables d'environnement `TOTAL_BUDGET`, `SIMPLE_RATIO`, `COMBO_SHARE`,
> `MAX_STAKE_PER_HORSE`) sont automatiquement convertis vers les clÃ©s
> officielles `BUDGET_TOTAL`, `SP_RATIO`, `COMBO_RATIO` et `MAX_VOL_PAR_CHEVAL`.


Ces seuils peuvent Ãªtre surchargÃ©s lors de l'exÃ©cution du pipeline avec les
options `--ev-global`, `--roi-global` et `--min-payout` :

```bash
python pipeline_run.py analyse \
  --ev-global 0.35 --roi-global 0.25 --min-payout 12 \
  --calibration config/payout_calibration.yaml
```

**SP Dutching (placÃ©)** : EV(â‚¬) par jambe = `stake * [ p*(odds-1) âˆ’ (1âˆ’p) ]
**CombinÃ©s (CP/Trio/ZE4)** : via `simulate_wrapper` + calibration `payout_calibration.yaml` (par dÃ©faut `config/payout_calibration.yaml`, avec repli automatique vers `calibration/payout_calibration.yaml`, surchargeable via `--calibration`).


### Calibration, budget & `ALERTE_VALUE`

- Les fichiers `calibration/payout_calibration.yaml` et `calibration/probabilities.yaml` doivent Ãªtre prÃ©sents avant toute
  analyse. Ils calibrent respectivement les gains des combinÃ©s et les probabilitÃ©s de base. Mettre ces fichiers Ã  jour
  rÃ©guliÃ¨rement avec `calibrate_simulator.py` ou `recalibrate_payouts_pro.py`.
- La calibration `calibration/p_true_model.yaml` n'est utilisÃ©e que si `n_samples` et `n_races` dÃ©passent `P_TRUE_MIN_SAMPLES`.
  Tant que ce seuil n'est pas atteint, le pipeline revient sur l'heuristique interne : rÃ©alimenter le modÃ¨le avec davantage de
  courses avant de rÃ©activer la calibration.
- Le budget total (`BUDGET_TOTAL`) est rÃ©parti entre paris simples et combinÃ©s selon `SP_RATIO` et `COMBO_RATIO`
  (par dÃ©faut **60â€¯% / 40â€¯%**). Modifier ces variables pour ajuster la rÃ©partition.
- Lorsqu'une combinaison prÃ©sente Ã  la fois un EV Ã©levÃ© et un payout attendu important, un drapeau `ALERTE_VALUE` est posÃ©
  sur le ticket. Ce flag est propagÃ© jusqu'au `tracking.csv` pour attirer l'attention sur ces cas Ã  surveiller.
### â™»ï¸ Recalibrage des payouts

Le script `recalibrate_payouts_pro.py` met Ã  jour `calibration/payout_calibration.yaml`
Ã  partir de rapports JSON (champ `abs_error_pct`) collectÃ©s aprÃ¨s les courses.

```bash
python recalibrate_payouts_pro.py --history data/results/*.json \
  --out calibration/payout_calibration.yaml
```

Si l'erreur moyenne dÃ©passe **15â€¯%** pour les combinÃ©s (CP/TRIO/ZE4), le
champ `PAUSE_EXOTIQUES` est positionnÃ© Ã  `true` afin de bloquer les paris
combinÃ©s jusqu'Ã  la prochaine calibration.

### ğŸ“Š Closing Line Value (CLV)

Chaque ticket conserve maintenant la cote d'ouverture et la cote de clÃ´ture
observÃ©e au moment du dÃ©part. Le **CLV** est dÃ©fini comme
`(closing_odds - open_odds) / open_odds`. Un CLV positif signifie que le
marchÃ© est allÃ© dans notre sens et corrÃ¨le gÃ©nÃ©ralement avec un **ROI rÃ©el**
supÃ©rieur.

### ğŸ“‰ Risque de ruine

`compute_ev_roi` renvoie un champ `risk_of_ruin` qui approxime la probabilitÃ© de
perdre l'intÃ©gralitÃ© du bankroll sur l'ensemble des tickets. L'approximation
utilise `exp(-2 * EV * bankroll / variance)` : une variance Ã©levÃ©e ou un
bankroll rÃ©duit augmentent ce risque qui tend vers `1`. Pour maintenir un
risque cible (ex. 1 %), ajuster `KELLY_CAP` : diminuer ce cap rÃ©duit les mises,
la variance et donc le `risk_of_ruin`.

### ğŸ¯ Limite de variance

Un paramÃ¨tre optionnel `variance_cap` permet de plafonner la volatilitÃ© globale.
Si la variance cumulÃ©e des tickets dÃ©passe `variance_cap * bankroll^2`, les mises
sont rÃ©duites proportionnellement et le panier est signalÃ© comme trop risquÃ©.

### ğŸ¤– Autoâ€‘sÃ©lection des tickets

Chaque appel Ã  `compute_ev_roi` renvoie dÃ©sormais une liste `ticket_metrics` oÃ¹
chaque ticket est dÃ©crit par :

- `kelly_stake` â€“ mise recommandÃ©e par Kelly avant plafonnement,
- `stake` â€“ mise rÃ©ellement engagÃ©e aprÃ¨s cap `kelly_cap`,
- `ev` â€“ espÃ©rance de gain en euros,
- `roi` â€“ retour sur investissement (`ev / stake`),
- `variance` â€“ variance de la mise,
- `clv` â€“ *closing line value*.

Ces mÃ©triques permettent d'automatiser la sÃ©lection des tickets :
filtrer ceux dont le `roi` ou l'`ev` est nÃ©gatif, privilÃ©gier les meilleurs
rapports `ev/variance` ou encore appliquer des seuils personnalisÃ©s avant de
valider l'envoi des tickets.

### ğŸš€ Optimisation des simulations

`compute_ev_roi` mÃ©morise dÃ©sormais les probabilitÃ©s calculÃ©es par
`simulate_fn` pour chaque ensemble de `legs`. Ce cache activÃ© par dÃ©faut
(`cache_simulations=True`) Ã©vite de recalculer des combinaisons identiques et
rÃ©duit d'au moins **30â€¯%** le temps CPU mesurÃ© sur des tickets rÃ©currents.
Passer `cache_simulations=False` dÃ©sactive cette optimisation.

---

## â–¶ï¸ ExÃ©cutions manuelles (local)

Un `Makefile` simplifie les commandes usuelles : `make venv` prÃ©pare l'environnement virtuel, `make test` lance la suite `pytest`, tandis que `make run-h30` et `make run-h5` enveloppent l'appel `analyse_courses_du_jour_enrichie.py` ci-dessous (ex. `URL="https://www.zeturf.fr/fr/course/..."`).

### GÃ©nÃ©rer le planning du jour
```bash
python scripts/online_fetch_zeturf.py \
  --mode planning \
  --out data/planning/$(date +%F).json \
  --sources config/sources.yml
```

### Forcer une fenÃªtre (ex : R1C3 Ã  Hâ€‘30)
# Le dossier doit contenir un snapshot (ex: snapshot_H30.json)
```bash
python scripts/runner_chain.py data/R1C3 --phase H30
```

### Lancer lâ€™analyse Hâ€‘5
# Le dossier doit contenir snapshot_H5.json, je_stats.csv, et chronos.csv
```bash
python scripts/runner_chain.py data/R1C3 --phase H5 \
  --budget 5 --calibration calibration/payout_calibration.yaml
```

### Postâ€‘course : arrivÃ©e + MAJ Excel
# Le dossier doit contenir arrivee_officielle.json
```bash
python scripts/runner_chain.py data/R1C3 --phase RESULT
```

Le script autonome `post_course.py` accepte dÃ©sormais l'option `--places`
pour indiquer le nombre de positions rÃ©munÃ©rÃ©es Ã  considÃ©rer (1 par dÃ©faut).
Par exempleâ€¯:

```bash
python post_course.py --arrivee arrivee.json --tickets tickets.json --places 3
```

### Calculer EV/ROI via la CLI
```bash
python cli_ev.py --tickets tickets.json --budget 100 \
  --ev-threshold 5 --roi-threshold 0.2
```

### Calibrer le simulateur
```bash
python calibration/calibrate_simulator.py --results data/results.csv

```
### Analyse des courses du jour (Geny)

#### Usage

```bash
python fetch_reunions_geny.py --date YYYY-MM-DD --out data/reunions.json
python analyse_courses_du_jour_enrichie.py --reunions-file data/reunions.json --budget <B> --kelly <K>
```

Le second script dÃ©clenche automatiquement les phases **H30** puis **H5** pour chaque rÃ©union franÃ§aise listÃ©e dans `data/reunions.json`.

#### DÃ©pendances

- `beautifulsoup4`
- `requests`

#### Mise Ã  jour du planning Excel

Un utilitaire dÃ©diÃ© `scripts/update_excel_planning.py` permet d'alimenter
l'onglet **Planning** du classeur `modele_suivi_courses_hippiques.xlsx`. Le
script gÃ¨re les phases H-30 (collecte) et H-5 (analyse) en rÃ©alisant un
*upsert* basÃ© sur la clÃ© `(Date, RÃ©union, Course)`.

```bash
# Phase H-30 : collecte de toutes les rÃ©unions franÃ§aises du jour
export TZ=Europe/Paris
while read -r URL; do
  python online_fetch_zeturf.py --reunion-url "$URL" --snapshot H-30 --out data/meeting
done < sources.txt

python scripts/update_excel_planning.py \
  --phase H30 \
  --in data/meeting \
  --excel modele_suivi_courses_hippiques.xlsx

# Phase H-5 : mise Ã  jour course par course aprÃ¨s l'analyse
python scripts/update_excel_planning.py \
  --phase H5 \
  --in data/R4C5 \
  --excel modele_suivi_courses_hippiques.xlsx
```

Les colonnes suivantes sont ajoutÃ©es si nÃ©cessaire :
`Date`, `RÃ©union`, `Course`, `Hippodrome`, `Heure`, `Partants`, `Discipline`,
`Statut H-30`, `Statut H-5`, `Jouable H-5`, `Tickets H-5`, `Commentaires`.
La phase H-5 synthÃ©tise les tickets au format compact (`SP:3-5@2.0 | CPL:1-3@1.5`)
et alimente les drapeaux `Statut H-5`/`Jouable H-5` selon l'analyse
(`abstain`).

#### Autres usages

- Exemple pour traiter toutes les rÃ©unions du jour :
  ```bash
  python analyse_courses_du_jour_enrichie.py --from-geny-today --phase H5 --budget 5
  ```
  Pour lancer l'analyse depuis un fichier de rÃ©unions (`fetch_reunions_geny.py`) :
  ```bash
  python analyse_courses_du_jour_enrichie.py --reunions-file data/reunions.json
  ```
- Pour une rÃ©union spÃ©cifique issue de ZEturf :
  ```bash
  python analyse_courses_du_jour_enrichie.py --reunion-url https://www.zeturf.fr/fr/reunion/... --phase H5
  ```
  Les sorties sont Ã©crites sous `data/RxCy/` (ex. `data/R1C3/`).
- Pour une course isolÃ©e, la fonction `write_snapshot_from_geny` permet d'Ã©crire un snapshot `H30`/`H5`.
- Limitations : les cotes Geny sont chargÃ©es dynamiquement et peuvent varier aprÃ¨s captureâ€¯; aucune authentification n'est requise.

### Smoke test H-5 express

Un utilitaire shell `scripts/smoke_h5.sh` orchestre une analyse Hâ€‘5 complÃ¨te en
pilotant `analyse_courses_du_jour_enrichie.py`, puis vÃ©rifie la prÃ©sence des
principaux artefacts (`analysis_H5.json`, `per_horse_report.csv`,
`tracking.csv`, `snapshot_H5.json`). Les sorties sont Ã©crites dans le dossier
deterministe `out_smoke_h5/`.

```bash
# URL optionnelle (par dÃ©faut : rÃ©union de dÃ©monstration ZEturf)
scripts/smoke_h5.sh "https://www.zeturf.fr/fr/meeting/2024-09-25/paris-vincennes"

# Ou bien laissez le script utiliser son URL d'exemple
scripts/smoke_h5.sh
```

Le script accepte Ã©galement la variable d'environnement `PYTHON` pour pointer
vers un interprÃ©teur spÃ©cifique et supprime `out_smoke_h5/` avant chaque
exÃ©cution afin de fournir un Ã©tat propre.

---

## ğŸ§¾ Artifacts produits

- `data/snapshots/R1C3/snapshot_H30.json` et `snapshot_H5.json`
- `data/R1C3/analysis_H5.json` â€“ mÃ©ta, tickets (EV/ROI, flags), validation, `ev_ok`, `abstain`
- `data/R1C3/per_horse_report.csv` â€“ rapport par cheval (`num`, `nom`, `p_finale`, `j_rate`, `e_rate`, `chrono_ok`)
- `data/R1C3/tracking.csv` â€“ ligne synthÃ¨se (`ALERTE_VALUE` ajoutÃ© si alerte)
- `data/results/YYYY-MM-DD_arrivees.json`
- `excel/modele_suivi_courses_hippiques.xlsx` (mis Ã  jour)

Extrait `analysis_H5.json` :
```json
{
  "meta": {"reunion":"R1","course":"C3","date":"2025-09-07"},
  "tickets": [
    {"id":"SP1","type":"SP","legs":[{"horse":"6","p":0.38,"odds":2.9}, {"horse":"3","p":0.32,"odds":3.4}],"ev_ratio":0.31},
    {"id":"CP1","type":"CP","legs":["6","3"],"ev_check":{"ev_ratio":0.41,"payout_expected":12.5}}
  ],
  "validation": {
    "sp":{"status":"ok","roi_est":0.31},
    "exotics":{"validated":true},
    "roi_global_est":0.27
  },
  "ev_ok": true,
  "abstain": false
}
```

Le fichier `per_horse_report.csv` est sauvegardÃ© dans le mÃªme dossier que l'analyse et contient une ligne par partant avec les
colonnes listÃ©es ci-dessus.

---

## âœ… Checkâ€‘list de mise en route

1. Pousser la structure de dÃ©pÃ´t ciâ€‘dessus.  
2. Ajouter **`requirements.txt`** et installer en local (facultatif).  
3. CrÃ©er le **Secret** `GCS_SERVICE_KEY_B64` et les **Variables** `GCS_BUCKET` / `GCS_PREFIX` (optionnelle) / `GOOGLE_CLOUD_PROJECT` (optionnelle).
4. VÃ©rifier que les scripts sous `scripts/` existent bien aux bons chemins.  
5. Laisser tourner les 3 workflows (planning, scheduler, results).  
6. ContrÃ´ler sur **Actions** les logs dâ€™exÃ©cution et la crÃ©ation des JSON/Excel.
7. Tester la synchro GCS : `python scripts/drive_sync.py --upload-glob "data/**/*.json"` puis un `--download` vers un dossier temporaire.
---

## ğŸ› ï¸ DÃ©pannage (FAQ)

- **Les workflows ne se dÃ©clenchent pas** â†’ vÃ©rifier le dossier **`.github/workflows/`** (orthographe) et la branche par dÃ©faut.  
- **ArrivÃ©es non trouvÃ©es** â†’ voir logs `get_arrivee_geny.py`, parfois page retardÃ©e ; relancer manuellement `post_results.yml`.  
- **Upload GCS manquant** â†’ secrets/variables absents (`GCS_SERVICE_KEY_B64`, `GCS_BUCKET`, `GCS_PREFIX`/`GOOGLE_CLOUD_PROJECT`) ou droits insuffisants sur le bucket. 
- **EV combinÃ©s = insufficient_data** â†’ calibration absente/vides (`calibration/payout_calibration.yaml`) ou p_place non enrichies.  
- **Excel non mis Ã  jour** â†’ chemin `--excel` correct ? vÃ©rifier permissions du runner (commit autorisÃ©).  

---

## ğŸ”’ Bonnes pratiques

- Ne **jamais** committer de secrets (`credentials.json`, `.env`).  
- En prod GitHub, prÃ©fÃ©rer des **dossiers persistants** (artifacts/GCS) car le runner est Ã©phÃ©mÃ¨re.  
- Ajouter une **tempo** (0.5â€“1s) dans les fetchs pour Ã©viter un blocage des sites sources.  

---

## Â© Licence & contact

Projet privÃ© **Analyse Hippique â€“ GPI v5.1**.  
Auteur : Deletrez â€” Support technique : via issues privÃ©es du repo.
