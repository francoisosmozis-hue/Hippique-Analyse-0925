# Analyse Hippique ‚Äì GPI v5.1 (Budget 5‚Ç¨ / EV+)

Pipeline **pro** pour planifier, capturer H‚Äë30 / H‚Äë5, analyser et consigner chaque course (tickets, EV/ROI, pastille verte/rouge) avec export Google Cloud Storage + mise √† jour Excel.

---

## üîé Vue d‚Äôensemble

- **09:00 Paris** : g√©n√©ration du **planning du jour** (r√©unions, courses, horaires, URLs).
- **Scheduler (*/5 min)** : d√©clenche auto les fen√™tres **H‚Äë30** (snapshots cotes + stats) et **H‚Äë5** (analyse GPI v5.1 + tickets).
- **Post‚Äëresults (*/15 min)** : r√©cup√©ration **arriv√©es officielles**, **mise √† jour Excel** (ROI r√©el), **upload GCS**.

**Standards verrouill√©s** (GPI v5.1) :
- Budget **max 5 ‚Ç¨** / course, **2 tickets max** (SP + 1 combin√© √©ventuel, configurable via `MAX_TICKETS_SP`).
- **EV globale ‚â• +35 %** et **ROI estim√© global ‚â• +25 %** (**ROI SP ‚â• +10 %**) pour valider le **vert**.
- Combin√©s uniquement si **payout attendu > 12 ‚Ç¨** (calibration).
- **KELLY_FRACTION = 0.5** : moiti√© de Kelly pour r√©duire la variance au prix d'une EV moindre; cap 60 % par cheval.
- **MIN_STAKE_SP = 0.10** : mise minimale par ticket SP, √©vite les micro-mises (r√©duit variance) mais peut bloquer un peu d'EV.
- **ROUND_TO_SP = 0.10** : arrondi des mises SP √† 0,10 ‚Ç¨; utiliser `0` pour d√©sactiver l'arrondi sans provoquer de crash tout en conservant le calcul EV/ROI.
- **SHARPE_MIN = 0.5** : seuil minimal de ratio EV/œÉ; filtre les paris √† variance trop √©lev√©e.

---

## üóÇÔ∏è Arborescence

```
analyse-hippique/
‚îú‚îÄ README.md
‚îú‚îÄ requirements.txt
‚îú‚îÄ .env.example
‚îú‚îÄ gpi_v51.yml
‚îú‚îÄ calibration/
‚îÇ  ‚îú‚îÄ payout_calibration.yaml
‚îÇ  ‚îú‚îÄ probabilities.yaml
‚îÇ  ‚îî‚îÄ calibrate_simulator.py
‚îú‚îÄ config/
‚îÇ  ‚îú‚îÄ sources.yml
‚îÇ  ‚îî‚îÄ meetings.json    # exemple de planning (reunion/course/time)
‚îú‚îÄ data/
‚îÇ  ‚îú‚îÄ planning/          # programmes du jour (JSON)
‚îÇ  ‚îú‚îÄ snapshots/         # H-30 / H-5 (cotes + stats)
‚îÇ  ‚îú‚îÄ analyses/          # analyses H-5 (tickets + pastille)
‚îÇ  ‚îî‚îÄ results/           # arriv√©es + exports Excel/CSV
‚îú‚îÄ excel/
‚îÇ  ‚îî‚îÄ modele_suivi_courses_hippiques.xlsx
‚îú‚îÄ scripts/
‚îÇ  ‚îú‚îÄ runner_chain.py
‚îÇ  ‚îú‚îÄ fetch_schedule.py
‚îÇ  ‚îú‚îÄ pipeline_run.py
‚îÇ  ‚îú‚îÄ simulate_ev.py
‚îÇ  ‚îú‚îÄ simulate_wrapper.py
‚îÇ  ‚îú‚îÄ validator_ev.py (ou validator_ev_v2.py)
‚îÇ  ‚îú‚îÄ online_fetch_zeturf.py
‚îÇ  ‚îú‚îÄ fetch_je_stats.py
‚îÇ  ‚îú‚îÄ fetch_je_chrono.py
‚îÇ  ‚îú‚îÄ p_finale_export.py
‚îÇ  ‚îú‚îÄ get_arrivee_geny.py
‚îÇ  ‚îú‚îÄ update_excel_with_results.py
‚îÇ  ‚îî‚îÄ drive_sync.py
‚îî‚îÄ .github/workflows/
   ‚îú‚îÄ daily_planning.yml
   ‚îú‚îÄ race_scheduler.yml
   ‚îî‚îÄ post_results.yml
```

### Configuration des sources

Le fichier `config/sources.yml` pointe vers l'API de snapshot Zeturf :

```yaml
zeturf:
  url: "https://www.zeturf.fr/rest/api/race/{course_id}"
```

Remplacez `{course_id}` par l'identifiant num√©rique de la course avant d'appeler
`scripts/online_fetch_zeturf.py --mode h30` ou `--mode h5`.
Le workflow `gpi_v51.yml` fait cette substitution automatiquement via son entr√©e
`course_id`. Pour un test local‚ÄØ:

```bash
COURSE_ID=123456 sed -i "s/{course_id}/$COURSE_ID/" config/sources.yml
python scripts/online_fetch_zeturf.py --mode h30 --out data/h30/h30.json
```

---

## ‚öôÔ∏è Installation locale

1) **Python 3.12+**
2) D√©pendances :
```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```
**Ex. de packages** : `pandas`, `openpyxl`, `pyyaml`, `requests`, `google-api-python-client`, `google-auth`, `google-auth-httplib2`, `google-auth-oauthlib` ‚Ä¶

> **SciPy facultatif** : si `scipy` n'est pas install√©, `optimize_stake_allocation` utilisera un optimiseur de secours plus simple.

3) Variables locales : dupliquez `.env.example` en `.env` et ajustez si besoin.

Variables disponibles :

| Variable | D√©faut | Description |
| --- | --- | --- |
| `ALLOW_HEURISTIC` | `0` | d√©sactive les heuristiques de backup (`1` pour les autoriser). |

Afin de tester localement ou en CI, un fichier d'exemple `config/meetings.json`
illustre le format attendu (`reunion`, `course`, `time`).
Un planning r√©el peut √™tre g√©n√©r√© via `python scripts/fetch_schedule.py --out config/meetings.json`.

---

## üîê Secrets & Variables GitHub

Dans **Settings ‚Üí Secrets and variables ‚Üí Actions** du repo, cr√©er :

**Secrets**
- `GCS_SERVICE_KEY_B64` ‚Üí cl√© de service Google Cloud encod√©e en base64 (`credentials.json`)
- `ZETURF_LOGIN` ‚Üí identifiant pour la connexion Zeturf
- `ZETURF_PASSWORD` ‚Üí mot de passe pour la connexion Zeturf
- `PYPI_EXTRA_INDEX` *(optionnel)* ‚Üí URL d'un d√©p√¥t PyPI priv√©
- `GENY_COOKIE` *(optionnel)* ‚Üí cookie d'acc√®s pour r√©cup√©rer les donn√©es Geny

**Variables**
- `GCS_BUCKET` ‚Üí bucket Google Cloud Storage de destination
- `GCS_PREFIX` *(optionnel)* ‚Üí pr√©fixe appliqu√© aux objets upload√©s (ex: `hippiques/prod`)
- `GOOGLE_CLOUD_PROJECT` *(optionnel)* ‚Üí projet GCP utilis√© pour l'authentification
- `MEETING_URLS` ‚Üí r√©unions du jour pour H‚Äë30
- `COURSES_URLS` ‚Üí cours suppl√©mentaires pour H‚Äë5

> ‚ö†Ô∏è **S√©curit√© :** ne commitez jamais `credentials.json` ni la valeur de ces secrets et √©vitez toute fuite (logs, issues, captures d'√©cran).

---

## üß∞ Workflows GitHub

### 1) `daily_planning.yml` ‚Äî 09:00 Paris
- Appelle `scripts/online_fetch_zeturf.py --mode planning`
- √âcrit `data/planning/YYYY-MM-DD.json`

### 2) `race_scheduler.yml` ‚Äî toutes les 5 min
- Appelle `scripts/runner_chain.py` avec fen√™tres **H‚Äë30** puis **H‚Äë5**.
- **H‚Äë30** : snapshots cotes + stats (JSON).  
-- **H‚Äë5** : enrichissement J/E + chronos (si dispo) ‚Üí **pipeline** (tickets, EV/ROI) ‚Üí **pastille** (VERT/ROUGE) ‚Üí export JSON/CSV ‚Üí **upload GCS**.

### 3) `post_results.yml` ‚Äî toutes les 15 min
- `get_arrivee_geny.py` ‚Üí `data/results/ARRIVEES.json`
- `update_excel_with_results.py` ‚Üí met √† jour `excel/modele_suivi_courses_hippiques.xlsx`
- Upload Excel + r√©sultats sur GCS

### Lancer les workflows manuellement

Les trois workflows ci-dessus sont planifi√©s mais peuvent aussi √™tre d√©clench√©s √† la demande depuis l'onglet **Actions** du d√©p√¥t
via le bouton **Run workflow** ou en ligne de commande‚ÄØ:

```bash
gh workflow run race_scheduler.yml
```

Les fichiers g√©n√©r√©s apparaissent ensuite sous `data/` et `excel/`.

### D√©clenchement via API

Un **Personal Access Token** (`GH_PAT`) disposant des scopes `repo` et `workflow` est requis.

#### Mode H‚Äë30

```bash
curl -X POST \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer GH_PAT" \
  https://api.github.com/repos/OWNER/REPO/actions/workflows/hippique-pipeline.yml/dispatches \
  -d '{"ref":"main","inputs":{"mode":"h30","date":"YYYY-MM-DD","meeting":"R1","race":"C1","hippodrome":"PARIS-VINCENNES","discipline":"trot","course_id":"123456"}}'
```

#### Mode H‚Äë5

```bash
curl -X POST \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer GH_PAT" \
  https://api.github.com/repos/OWNER/REPO/actions/workflows/hippique-pipeline.yml/dispatches \
  -d '{"ref":"main","inputs":{"mode":"h5","date":"YYYY-MM-DD","meeting":"R1","race":"C1","hippodrome":"PARIS-VINCENNES","discipline":"trot","course_id":"123456"}}'
```

#### Mode post-course

```bash
curl -X POST \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer GH_PAT" \
  https://api.github.com/repos/OWNER/REPO/actions/workflows/hippique-pipeline.yml/dispatches \
  -d '{"ref":"main","inputs":{"mode":"post","date":"YYYY-MM-DD","meeting":"R1","race":"C1","hippodrome":"PARIS-VINCENNES","discipline":"trot","course_id":"123456"}}'
```

> Rappel : `date` suit le format `YYYY-MM-DD`. Les champs `meeting` et `race` utilisent la notation `R#/C#` (ex. `R1`, `C5`) et `course_id` est l'identifiant num√©rique de la course.


### Alertes dans les fichiers de suivi

Chaque course analys√©e ajoute une ligne dans `data/RxCy/tracking.csv`. Si une colonne `ALERTE_VALUE` est pr√©sente, le combin√©
associ√© affiche un EV > 0.5 et un payout attendu > 20 ‚Ç¨ et m√©rite une v√©rification manuelle.

### ‚òÅÔ∏è Synchronisation Google Cloud Storage

1. Cr√©ez un **compte de service** dans la console Google Cloud et donnez-lui
   l'acc√®s en √©criture au bucket cible.
2. D√©finissez les variables d'environnement suivantes :
   - `GCS_BUCKET` (obligatoire) ‚Üí nom du bucket de destination ;
   - `GCS_SERVICE_KEY_B64` (obligatoire) ‚Üí contenu base64 du `credentials.json`
     du compte de service ;
   - `GCS_PREFIX` *(optionnel)* ‚Üí sous-dossier virtuel (pr√©fixe) o√π ranger les
     artefacts ;
   - `GOOGLE_CLOUD_PROJECT` *(optionnel)* ‚Üí projet GCP pour journaliser les
     acc√®s.

Le module `scripts/drive_sync.py` expose `upload_file`, `download_file` et
`push_tree` bas√©s sur `google-cloud-storage`.

```bash
python scripts/drive_sync.py \
  --upload-glob "data/results/**/*.json" \
  --upload-glob "excel/*.xlsx"
```

Plusieurs motifs `--upload-glob` peuvent √™tre fournis.  Pour t√©l√©charger un
objet : `python scripts/drive_sync.py --download chemin/objet.json destination.json`.

### R√©cup√©rer les donn√©es archiv√©es

Pour rapatrier les fichiers `snapshot_*.json` et `analysis*.json` d'une date
pr√©cise, utilisez :

```bash
export GCS_BUCKET="<bucket>"
export GCS_SERVICE_KEY_B64="$(base64 -w0 credentials.json)"
python scripts/restore_from_drive.py --date YYYY-MM-DD --dest dossier_sortie
```

Ajoutez √©ventuellement `GCS_PREFIX` pour cibler un sous-dossier. Les fichiers
correspondants sont t√©l√©charg√©s dans le dossier indiqu√© par `--dest`.

---

## üßÆ R√®gles EV/ROI (GPI v5.1)

| R√®gle | Valeur |
|---|---|
| Budget max par course | **5 ‚Ç¨** |
| Tickets max | **2** (SP + 1 combin√©) |
| Partage SP / Combin√©s | **60% / 40%** |
| Cap Kelly par cheval (`KELLY_FRACTION`) | **60 %** |
| EV globale (combin√©s) | **‚â• +35 %** |
| ROI estim√© SP | **‚â• +10 %** |
| ROI estim√© global | **‚â• +25 %** |
| Payout min combin√©s | **> 12 ‚Ç¨** |
| Mise minimale SP (`MIN_STAKE_SP`) | **0.10 ‚Ç¨** |
| Arrondi mise SP (`ROUND_TO_SP`) | **0.10 ‚Ç¨** (`0` d√©sactive l'arrondi sans provoquer d'erreur) |
| Sharpe min (`SHARPE_MIN`) | **0.5** |
| Coefficient de drift des cotes (`DRIFT_COEF`) | **0.05** |
| Coefficient bonus J/E (`JE_BONUS_COEF`) | **0.001** |
| Pastille **VERT** si | EV‚â•35% & ROI‚â•25% & (si combin√©s) payout>12‚Ç¨ |

### Variables de configuration principales

| Cl√© | Description |
| --- | --- |
| `BUDGET_TOTAL` | Budget maximum allou√© par course. |
| `SP_RATIO` | Part du budget d√©di√©e aux paris simples (SP). |
| `COMBO_RATIO` | Part du budget d√©di√©e aux combin√©s. |
| `EV_MIN_SP` | EV minimale requise pour les tickets SP (ratio du budget SP). |
| `EV_MIN_SP_HOMOGENEOUS` | Seuil EV SP appliqu√© lorsque le champ est consid√©r√© homog√®ne. |
| `EV_MIN_GLOBAL` | EV minimale globale pour valider l'√©mission des combin√©s. |
| `ROI_MIN_SP` | ROI minimal attendu pour les tickets simples (10‚ÄØ% par d√©faut). |
| `ROI_MIN_GLOBAL` | ROI minimal global attendu pour les combin√©s (25‚ÄØ% par d√©faut). |
| `MAX_VOL_PAR_CHEVAL` | Fraction maximale du budget sur un seul cheval. |
| `MIN_PAYOUT_COMBOS` | Gain minimal attendu pour autoriser un ticket combin√© (12‚ÄØ‚Ç¨ par d√©faut). |
| `EXOTIC_MIN_PAYOUT` | Alias de `MIN_PAYOUT_COMBOS` pour compatibilit√©. |
| `ALLOW_JE_NA` | Autorise l'absence de stats jockey/entra√Æneur lors de l'analyse. |
| `SNAPSHOTS` | Phases de collecte des cotes pour le drift (ex. `H30,H5`). |
| `DRIFT_TOP_N` | Nombre maximal de steams/drifts conserv√©s. |
| `DRIFT_MIN_DELTA` | Variation minimale de cote pour √™tre retenue comme drift/steam. |
| `P_TRUE_MIN_SAMPLES` | Historique minimal (√©chantillons/courses) pour activer le mod√®le `p_true`. |

> ‚ÑπÔ∏è Le pipeline accepte √©galement certains alias conviviaux : `TotalBudget`,
> `simpleShare`, `comboShare` ou `maxStakePerHorse` (et leurs √©quivalents en
> variables d'environnement `TOTAL_BUDGET`, `SIMPLE_RATIO`, `COMBO_SHARE`,
> `MAX_STAKE_PER_HORSE`) sont automatiquement convertis vers les cl√©s
> officielles `BUDGET_TOTAL`, `SP_RATIO`, `COMBO_RATIO` et `MAX_VOL_PAR_CHEVAL`.


Ces seuils peuvent √™tre surcharg√©s lors de l'ex√©cution du pipeline avec les
options `--ev-global`, `--roi-global` et `--min-payout` :

```bash
python pipeline_run.py analyse --ev-global 0.35 --roi-global 0.25 --min-payout 12
```

**SP Dutching (plac√©)** : EV(‚Ç¨) par jambe = `stake * [ p*(odds-1) ‚àí (1‚àíp) ]
**Combin√©s (CP/Trio/ZE4)** : via `simulate_wrapper` + calibration `payout_calibration.yaml`.

### Calibration, budget & `ALERTE_VALUE`

- Les fichiers `calibration/payout_calibration.yaml` et `calibration/probabilities.yaml` doivent √™tre pr√©sents avant toute
  analyse. Ils calibrent respectivement les gains des combin√©s et les probabilit√©s de base. Mettre ces fichiers √† jour
  r√©guli√®rement avec `calibrate_simulator.py` ou `recalibrate_payouts_pro.py`.
- La calibration `calibration/p_true_model.yaml` n'est utilis√©e que si `n_samples` et `n_races` d√©passent `P_TRUE_MIN_SAMPLES`.
  Tant que ce seuil n'est pas atteint, le pipeline revient sur l'heuristique interne : r√©alimenter le mod√®le avec davantage de
  courses avant de r√©activer la calibration.
- Le budget total (`BUDGET_TOTAL`) est r√©parti entre paris simples et combin√©s selon `SP_RATIO` et `COMBO_RATIO`
  (par d√©faut **60‚ÄØ% / 40‚ÄØ%**). Modifier ces variables pour ajuster la r√©partition.
- Lorsqu'une combinaison pr√©sente √† la fois un EV √©lev√© et un payout attendu important, un drapeau `ALERTE_VALUE` est pos√©
  sur le ticket. Ce flag est propag√© jusqu'au `tracking.csv` pour attirer l'attention sur ces cas √† surveiller.
### ‚ôªÔ∏è Recalibrage des payouts

Le script `recalibrate_payouts_pro.py` met √† jour `calibration/payout_calibration.yaml`
√† partir de rapports JSON (champ `abs_error_pct`) collect√©s apr√®s les courses.

```bash
python recalibrate_payouts_pro.py --history data/results/*.json \
  --out calibration/payout_calibration.yaml
```

Si l'erreur moyenne d√©passe **15‚ÄØ%** pour les combin√©s (CP/TRIO/ZE4), le
champ `PAUSE_EXOTIQUES` est positionn√© √† `true` afin de bloquer les paris
combin√©s jusqu'√† la prochaine calibration.

### üìä Closing Line Value (CLV)

Chaque ticket conserve maintenant la cote d'ouverture et la cote de cl√¥ture
observ√©e au moment du d√©part. Le **CLV** est d√©fini comme
`(closing_odds - open_odds) / open_odds`. Un CLV positif signifie que le
march√© est all√© dans notre sens et corr√®le g√©n√©ralement avec un **ROI r√©el**
sup√©rieur.

### üìâ Risque de ruine

`compute_ev_roi` renvoie un champ `risk_of_ruin` qui approxime la probabilit√© de
perdre l'int√©gralit√© du bankroll sur l'ensemble des tickets. L'approximation
utilise `exp(-2 * EV * bankroll / variance)` : une variance √©lev√©e ou un
bankroll r√©duit augmentent ce risque qui tend vers `1`. Pour maintenir un
risque cible (ex. 1 %), ajuster `KELLY_CAP` : diminuer ce cap r√©duit les mises,
la variance et donc le `risk_of_ruin`.

### üéØ Limite de variance

Un param√®tre optionnel `variance_cap` permet de plafonner la volatilit√© globale.
Si la variance cumul√©e des tickets d√©passe `variance_cap * bankroll^2`, les mises
sont r√©duites proportionnellement et le panier est signal√© comme trop risqu√©.

### ü§ñ Auto‚Äës√©lection des tickets

Chaque appel √† `compute_ev_roi` renvoie d√©sormais une liste `ticket_metrics` o√π
chaque ticket est d√©crit par :

- `kelly_stake` ‚Äì mise recommand√©e par Kelly avant plafonnement,
- `stake` ‚Äì mise r√©ellement engag√©e apr√®s cap `kelly_cap`,
- `ev` ‚Äì esp√©rance de gain en euros,
- `roi` ‚Äì retour sur investissement (`ev / stake`),
- `variance` ‚Äì variance de la mise,
- `clv` ‚Äì *closing line value*.

Ces m√©triques permettent d'automatiser la s√©lection des tickets :
filtrer ceux dont le `roi` ou l'`ev` est n√©gatif, privil√©gier les meilleurs
rapports `ev/variance` ou encore appliquer des seuils personnalis√©s avant de
valider l'envoi des tickets.

### üöÄ Optimisation des simulations

`compute_ev_roi` m√©morise d√©sormais les probabilit√©s calcul√©es par
`simulate_fn` pour chaque ensemble de `legs`. Ce cache activ√© par d√©faut
(`cache_simulations=True`) √©vite de recalculer des combinaisons identiques et
r√©duit d'au moins **30‚ÄØ%** le temps CPU mesur√© sur des tickets r√©currents.
Passer `cache_simulations=False` d√©sactive cette optimisation.

---

## ‚ñ∂Ô∏è Ex√©cutions manuelles (local)

### G√©n√©rer le planning du jour
```bash
python scripts/online_fetch_zeturf.py \
  --mode planning \
  --out data/planning/$(date +%F).json \
  --sources config/sources.yml
```

### Forcer une fen√™tre (ex : R1C3 √† H‚Äë30)
```bash
python scripts/runner_chain.py --reunion R1 --course C3 --phase H30 --ttl-hours 6
```

### Lancer l‚Äôanalyse H‚Äë5
```bash
python scripts/runner_chain.py --reunion R1 --course C3 --phase H5 \
  --budget 5 --calibration calibration/payout_calibration.yaml
```

### Post‚Äëcourse : arriv√©e + MAJ Excel
```bash
python scripts/runner_chain.py --reunion R1 --course C3 --phase RESULT \
  --excel excel/modele_suivi_courses_hippiques.xlsx
```

Le script autonome `post_course.py` accepte d√©sormais l'option `--places`
pour indiquer le nombre de positions r√©mun√©r√©es √† consid√©rer (1 par d√©faut).
Par exemple‚ÄØ:

```bash
python post_course.py --arrivee arrivee.json --tickets tickets.json --places 3
```

### Calculer EV/ROI via la CLI
```bash
python cli_ev.py --tickets tickets.json --budget 100 \
  --ev-threshold 5 --roi-threshold 0.2
```

### Calibrer le simulateur
```bash
python calibration/calibrate_simulator.py --results data/results.csv

```
### Analyse des courses du jour (Geny)

#### Usage

```bash
python fetch_reunions_geny.py --date YYYY-MM-DD --out data/reunions.json
python analyse_courses_du_jour_enrichie.py --reunions-file data/reunions.json --budget <B> --kelly <K>
```

Le second script d√©clenche automatiquement les phases **H30** puis **H5** pour chaque r√©union fran√ßaise list√©e dans `data/reunions.json`.

#### D√©pendances

- `beautifulsoup4`
- `requests`

#### Autres usages

- Exemple pour traiter toutes les r√©unions du jour :
  ```bash
  python analyse_courses_du_jour_enrichie.py --from-geny-today --phase H5 --budget 5
  ```
  Pour lancer l'analyse depuis un fichier de r√©unions (`fetch_reunions_geny.py`) :
  ```bash
  python analyse_courses_du_jour_enrichie.py --reunions-file data/reunions.json
  ```
- Pour une r√©union sp√©cifique issue de ZEturf :
  ```bash
  python analyse_courses_du_jour_enrichie.py --reunion-url https://www.zeturf.fr/fr/reunion/... --phase H5
  ```
  Les sorties sont √©crites sous `data/RxCy/` (ex. `data/R1C3/`).
- Pour une course isol√©e, la fonction `write_snapshot_from_geny` permet d'√©crire un snapshot `H30`/`H5`.
- Limitations : les cotes Geny sont charg√©es dynamiquement et peuvent varier apr√®s capture‚ÄØ; aucune authentification n'est requise.

---

## üßæ Artifacts produits

- `data/snapshots/R1C3/snapshot_H30.json` et `snapshot_H5.json`
- `data/R1C3/analysis_H5.json` ‚Äì m√©ta, tickets (EV/ROI, flags), validation, `ev_ok`, `abstain`
- `data/R1C3/per_horse_report.csv` ‚Äì rapport par cheval (`num`, `nom`, `p_finale`, `j_rate`, `e_rate`, `chrono_ok`)
- `data/R1C3/tracking.csv` ‚Äì ligne synth√®se (`ALERTE_VALUE` ajout√© si alerte)
- `data/results/YYYY-MM-DD_arrivees.json`
- `excel/modele_suivi_courses_hippiques.xlsx` (mis √† jour)

Extrait `analysis_H5.json` :
```json
{
  "meta": {"reunion":"R1","course":"C3","date":"2025-09-07"},
  "tickets": [
    {"id":"SP1","type":"SP","legs":[{"horse":"6","p":0.38,"odds":2.9}, {"horse":"3","p":0.32,"odds":3.4}],"ev_ratio":0.31},
    {"id":"CP1","type":"CP","legs":["6","3"],"ev_check":{"ev_ratio":0.41,"payout_expected":12.5}}
  ],
  "validation": {
    "sp":{"status":"ok","roi_est":0.31},
    "exotics":{"validated":true},
    "roi_global_est":0.27
  },
  "ev_ok": true,
  "abstain": false
}
```

Le fichier `per_horse_report.csv` est sauvegard√© dans le m√™me dossier que l'analyse et contient une ligne par partant avec les
colonnes list√©es ci-dessus.

---

## ‚úÖ Check‚Äëlist de mise en route

1. Pousser la structure de d√©p√¥t ci‚Äëdessus.  
2. Ajouter **`requirements.txt`** et installer en local (facultatif).  
3. Cr√©er le **Secret** `GCS_SERVICE_KEY_B64` et les **Variables** `GCS_BUCKET` / `GCS_PREFIX` (optionnelle) / `GOOGLE_CLOUD_PROJECT` (optionnelle).
4. V√©rifier que les scripts sous `scripts/` existent bien aux bons chemins.  
5. Laisser tourner les 3 workflows (planning, scheduler, results).  
6. Contr√¥ler sur **Actions** les logs d‚Äôex√©cution et la cr√©ation des JSON/Excel.
7. Tester la synchro GCS : `python scripts/drive_sync.py --upload-glob "data/**/*.json"` puis un `--download` vers un dossier temporaire.
---

## üõ†Ô∏è D√©pannage (FAQ)

- **Les workflows ne se d√©clenchent pas** ‚Üí v√©rifier le dossier **`.github/workflows/`** (orthographe) et la branche par d√©faut.  
- **Arriv√©es non trouv√©es** ‚Üí voir logs `get_arrivee_geny.py`, parfois page retard√©e ; relancer manuellement `post_results.yml`.  
- **Upload GCS manquant** ‚Üí secrets/variables absents (`GCS_SERVICE_KEY_B64`, `GCS_BUCKET`, `GCS_PREFIX`/`GOOGLE_CLOUD_PROJECT`) ou droits insuffisants sur le bucket. 
- **EV combin√©s = insufficient_data** ‚Üí calibration absente/vides (`calibration/payout_calibration.yaml`) ou p_place non enrichies.  
- **Excel non mis √† jour** ‚Üí chemin `--excel` correct ? v√©rifier permissions du runner (commit autoris√©).  

---

## üîí Bonnes pratiques

- Ne **jamais** committer de secrets (`credentials.json`, `.env`).  
- En prod GitHub, pr√©f√©rer des **dossiers persistants** (artifacts/GCS) car le runner est √©ph√©m√®re.  
- Ajouter une **tempo** (0.5‚Äì1s) dans les fetchs pour √©viter un blocage des sites sources.  

---

## ¬© Licence & contact

Projet priv√© **Analyse Hippique ‚Äì GPI v5.1**.  
Auteur : Deletrez ‚Äî Support technique : via issues priv√©es du repo.
